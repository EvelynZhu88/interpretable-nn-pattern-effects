{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbba3047-f803-4acb-a677-8feba2a8497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 01:35:50.176367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-06 01:35:50.282658: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-06 01:35:50.316926: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up for Zonal-Mean Out-of-Sample Test ---\n",
      "Loading normalization data...\n",
      "✅ Normalization data loaded successfully.\n",
      "[[[220.6603 ]\n",
      "  [220.86879]\n",
      "  [220.88463]\n",
      "  ...\n",
      "  [220.85564]\n",
      "  [220.6545 ]\n",
      "  [220.89789]]\n",
      "\n",
      " [[221.35854]\n",
      "  [221.40932]\n",
      "  [221.33986]\n",
      "  ...\n",
      "  [221.18336]\n",
      "  [221.2454 ]\n",
      "  [221.24274]]\n",
      "\n",
      " [[221.73988]\n",
      "  [221.76971]\n",
      "  [221.81885]\n",
      "  ...\n",
      "  [221.57878]\n",
      "  [221.65894]\n",
      "  [221.67375]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[250.342  ]\n",
      "  [250.36276]\n",
      "  [250.38281]\n",
      "  ...\n",
      "  [250.28914]\n",
      "  [250.30632]\n",
      "  [250.32236]]\n",
      "\n",
      " [[250.1685 ]\n",
      "  [250.17897]\n",
      "  [250.18936]\n",
      "  ...\n",
      "  [250.13574]\n",
      "  [250.14691]\n",
      "  [250.15811]]\n",
      "\n",
      " [[250.01157]\n",
      "  [250.01212]\n",
      "  [250.01262]\n",
      "  ...\n",
      "  [250.0096 ]\n",
      "  [250.0104 ]\n",
      "  [250.01102]]]\n",
      "[[[0.53236264]\n",
      "  [0.5272247 ]\n",
      "  [0.52714396]\n",
      "  ...\n",
      "  [0.52715623]\n",
      "  [0.53207755]\n",
      "  [0.52702093]]\n",
      "\n",
      " [[0.5789421 ]\n",
      "  [0.57852644]\n",
      "  [0.58601373]\n",
      "  ...\n",
      "  [0.57942045]\n",
      "  [0.58237875]\n",
      "  [0.58337593]]\n",
      "\n",
      " [[0.6280233 ]\n",
      "  [0.61705726]\n",
      "  [0.6132673 ]\n",
      "  ...\n",
      "  [0.62475264]\n",
      "  [0.6240839 ]\n",
      "  [0.61795306]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.0660723 ]\n",
      "  [1.068216  ]\n",
      "  [1.070278  ]\n",
      "  ...\n",
      "  [1.0605257 ]\n",
      "  [1.0623667 ]\n",
      "  [1.0641106 ]]\n",
      "\n",
      " [[1.0350556 ]\n",
      "  [1.0358478 ]\n",
      "  [1.0366572 ]\n",
      "  ...\n",
      "  [1.0323557 ]\n",
      "  [1.0332991 ]\n",
      "  [1.0342047 ]]\n",
      "\n",
      " [[1.0114971 ]\n",
      "  [1.0116093 ]\n",
      "  [1.0117126 ]\n",
      "  ...\n",
      "  [1.0110854 ]\n",
      "  [1.0112362 ]\n",
      "  [1.0113711 ]]]\n",
      "[[-4.96990870e-05 -4.15147497e-06 -3.53764990e-05  3.88544177e-05\n",
      "   9.47087028e-05  4.36328492e-07 -2.07785561e-05 -6.62456805e-05\n",
      "   1.86816378e-05 -9.91270554e-07 -1.61949894e-04  3.47368314e-07\n",
      "  -5.66168019e-05  1.01033351e-04  4.82503083e-06 -4.58653267e-05\n",
      "   1.50808683e-05  5.35328472e-05  2.08802248e-05 -3.92441470e-05\n",
      "   7.43156415e-05  5.30965190e-05  9.59541430e-05 -7.32735352e-05\n",
      "  -6.42504310e-05 -3.01024302e-05 -5.29906138e-05  1.22807414e-05\n",
      "   3.33558310e-05  8.03564617e-05 -5.56212945e-06 -1.53096244e-05\n",
      "  -4.54967776e-05 -3.75666132e-05  2.19604553e-05  1.81542309e-05\n",
      "   2.24836258e-05 -4.84070479e-05 -8.26694213e-06  8.69903488e-06\n",
      "   1.78343980e-05 -1.07705364e-05 -2.11682873e-05 -7.98947167e-06\n",
      "   2.38127341e-05  1.27096564e-05  1.92312855e-05  0.00000000e+00\n",
      "  -2.74293893e-06 -2.77894651e-06  1.04951832e-05  1.24618382e-05\n",
      "   3.40007932e-06  1.14112618e-06  4.41901739e-06  2.94766642e-06\n",
      "   3.67291705e-07  1.35220796e-06 -4.02703677e-07 -8.63655089e-07\n",
      "   4.41835573e-06 -1.02658987e-05 -8.02071372e-06 -1.14933373e-05\n",
      "   2.54224892e-06  2.69739985e-06  1.29415885e-05  3.10979376e-05\n",
      "  -7.46947808e-06  2.72546458e-05 -3.54569852e-06 -1.36860999e-05\n",
      "   3.27458179e-06  1.93806113e-06  9.16501631e-06  1.21833082e-05\n",
      "   2.95135997e-05  1.04824749e-05 -1.99397891e-05 -1.73472345e-05\n",
      "   2.22781709e-05 -1.79064136e-05  5.35794461e-05  4.17625670e-05\n",
      "   2.79673859e-05  9.47214085e-06  3.31906199e-06 -1.53265682e-05\n",
      "  -3.56327873e-05  2.47923545e-05 -3.53743817e-05 -3.13965902e-05\n",
      "  -2.10030757e-05 -3.15723919e-05  3.41014015e-06  2.86303512e-05\n",
      "  -2.94076945e-05  2.59297740e-05  1.03003176e-05  5.46469664e-07\n",
      "   7.62727632e-06  1.69426785e-05 -3.82380495e-05 -1.40429995e-06\n",
      "   2.23247685e-06  2.67092346e-05 -3.30783587e-05 -4.91822721e-06\n",
      "   1.23697009e-06  1.83639224e-06 -1.72625107e-06 -1.10755427e-05\n",
      "   9.54627467e-06  2.26255397e-05 -8.96485653e-06 -2.73647875e-05\n",
      "   1.08827953e-05  2.17846537e-06 -9.02310421e-06  1.29129940e-05\n",
      "  -1.87981334e-06  1.01928244e-05  4.52584936e-06  7.21212882e-06\n",
      "  -7.37416349e-06 -2.22771109e-06 -1.21766898e-05  2.68045505e-06\n",
      "   3.14008247e-07 -7.88118359e-06 -1.05004790e-06  9.35008575e-06\n",
      "   4.39187943e-06  3.94515882e-06  2.69064827e-07  1.90728244e-07\n",
      "   1.36504900e-06 -2.97725364e-07 -3.76836374e-06 -2.41728117e-06\n",
      "   6.00110570e-06  7.43982446e-06  1.75855221e-05 -1.57226532e-05\n",
      "   3.30635339e-06  1.45937056e-05  2.39874771e-05  2.58143373e-05\n",
      "  -2.66096849e-05 -1.51846552e-05 -1.26662349e-06  4.10466491e-05\n",
      "   2.18587866e-06  5.07454279e-05  2.60907509e-05  1.99736792e-06\n",
      "  -4.11906803e-05 -3.44868968e-05 -1.08086615e-05 -7.02298275e-05\n",
      "  -1.63051300e-05 -2.86833038e-05 -4.40988333e-05 -7.02446559e-05\n",
      "  -3.22078231e-05  3.94008894e-05 -7.38962553e-05 -3.14283607e-05\n",
      "   1.28441552e-05  8.72784076e-05  2.62263093e-05  1.94314453e-05\n",
      "  -2.34897234e-05  9.71868794e-05  1.50639235e-05 -1.16567491e-04\n",
      "   7.77935566e-05  1.23353879e-04 -4.60940828e-05  1.39858108e-04\n",
      "   1.20028468e-04  1.32093162e-04 -4.55942100e-05  4.71700769e-05\n",
      "  -9.84323196e-05 -4.95465829e-05  4.68947255e-05 -4.42428645e-05\n",
      "  -6.27253976e-05 -5.63626272e-05 -3.77445322e-05  4.98388836e-05]]\n",
      "[[1.0973109  1.0824621  1.0563043  1.0395298  1.007003   0.99404824\n",
      "  0.9929977  1.0172836  1.0252074  1.02295    1.0039859  0.97871083\n",
      "  0.9603413  1.0915927  1.155512   1.1342509  1.1117208  1.0810401\n",
      "  1.0350811  1.0410167  1.0657034  1.1423917  1.2854011  1.2903559\n",
      "  1.3984332  1.6196867  1.806462   1.5292431  1.1787045  1.1541508\n",
      "  1.2048951  1.1369466  1.0927495  1.1177882  1.1171037  0.98477334\n",
      "  0.8034918  0.706149   0.6769369  0.70219606 0.7353815  0.7688084\n",
      "  0.820716   0.8714903  0.91958934 0.9573134  0.9864344  1.0093541\n",
      "  1.0123469  0.99358416 0.97180814 0.94098413 0.90709233 0.8668251\n",
      "  0.83395773 0.8132406  0.78913367 0.7626166  0.7426297  0.74496555\n",
      "  0.74298626 0.7314164  0.7232275  0.7189779  0.7165103  0.7151861\n",
      "  0.71454567 0.7114773  0.7043037  0.6980428  0.69583356 0.6917958\n",
      "  0.6992176  0.724615   0.7551604  0.8000969  0.83987355 0.87118167\n",
      "  0.89374    0.9100166  0.9242894  0.89606524 0.86030173 0.8166181\n",
      "  0.7924389  0.72929597 0.66933954 0.62764305 0.63467175 0.6286943\n",
      "  0.7205463  0.8064955  0.90534383 0.9542627  1.0034527  1.041581\n",
      "  1.0801077  1.1341037  1.2127336  1.1899427  1.0368385  0.94627887\n",
      "  1.0071045  1.1476067  1.3172494  1.3353314  1.2565435  1.1766863\n",
      "  1.1373677  1.0733236  1.0298827  0.9509775  0.86813295 0.78662366\n",
      "  0.74326605 0.70152354 0.67734367 0.67548066 0.67746574 0.6819068\n",
      "  0.68443745 0.6976299  0.7105197  0.7344394  0.77668804 0.80349153\n",
      "  0.78380406 0.7544863  0.7411168  0.729058   0.7278986  0.7244216\n",
      "  0.74427086 0.7213294  0.6773121  0.64191896 0.65842545 0.64720404\n",
      "  0.64053833 0.65743273 0.66968906 0.6609214  0.6463825  0.63683903\n",
      "  0.6432292  0.65011126 0.6441236  0.6491223  0.65659845 0.6591661\n",
      "  0.6476441  0.6301889  0.6286639  0.64086986 0.6597247  0.6719179\n",
      "  0.6963264  0.7256853  0.7732042  0.7804626  0.75709724 0.7826509\n",
      "  0.8210744  0.8429399  0.88934094 0.92208207 0.99939954 1.0540527\n",
      "  1.0749724  1.1053805  1.204717   1.2860148  1.324984   1.3262571\n",
      "  1.3552252  1.3557556  1.4321339  1.4128596  1.3532271  1.3016504\n",
      "  1.3148628  1.3319511  1.3814138  1.4226357  1.4716313  1.5182605\n",
      "  1.578276   1.6483326  1.7207509  1.799886   1.884692   1.9520644 ]]\n",
      "\n",
      "Loading and preprocessing 4xCO2 test data...\n",
      "✅ Test data preprocessed.\n",
      "\n",
      "--- Running Ensemble Predictions for 4xCO2 ---\n",
      "    Loading and predicting with model: /ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model_2D_changedLRandKS/model_fold1_ens1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 01:35:54.594107: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-06 01:35:55.594398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31088 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: weighted_mse. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_model_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ens1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Loading and predicting with model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m pred_4xco2_norm \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(TS_4xCO2_norm)\n\u001b[1;32m     83\u001b[0m pred_4xco2_unnorm \u001b[38;5;241m=\u001b[39m pred_4xco2_norm \u001b[38;5;241m*\u001b[39m y_std \u001b[38;5;241m+\u001b[39m y_mean\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/generic_utils.py:769\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    767\u001b[0m     obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    770\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    771\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure this object is passed to the `custom_objects` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    773\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    774\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    775\u001b[0m         )\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function: weighted_mse. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# FINAL OUT-OF-SAMPLE TEST SCRIPT FOR 2D ZONAL-MEAN MODELS\n",
    "# ==========================================================\n",
    "# This script contains all necessary code and corrected paths.\n",
    "# Please use this to replace your entire out-of-sample notebook.\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from keras.models import load_model\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# --- 1. Configuration: Set ONE Correct Path for Model Results ---\n",
    "print(\"--- Setting up for Zonal-Mean Out-of-Sample Test ---\")\n",
    "\n",
    "# For CESM1:\n",
    "path_model_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model_2D_changedLRandKS'\n",
    "# For CESM2:\n",
    "#path_model_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM2/trained_model_2D_changedLRandKS'\n",
    "\n",
    "# Define variable names for your test files\n",
    "In_name = \"TS\"\n",
    "Out_name = \"TOA_anom\"\n",
    "\n",
    "# Define paths to your TWO separate 4xCO2 test files\n",
    "# # For CESM1:\n",
    "file_4xCO2_input = \"/ocean/projects/ees250004p/ezhu3/data/CESM1/test/test.4xCO2.ANN.new.nc\"\n",
    "file_4xCO2_output = \"/ocean/projects/ees250004p/ezhu3/data/CESM1/test/test.4xCO2.zmean.ANN.new.nc\"\n",
    "\n",
    "# For CESM2:\n",
    "# file_4xCO2_input = \"/ocean/projects/ees250004p/ezhu3/data/CESM2/test/test.CESM2-4xCO2.ANN.nc\"\n",
    "# file_4xCO2_output = \"/ocean/projects/ees250004p/ezhu3/data/CESM2/test/test.CESM2-4xCO2.zmean.ANN.nc\"\n",
    "\n",
    "# --- 2. Load Normalization Data from the Training Run ---\n",
    "print(\"Loading normalization data...\")\n",
    "normalization_path = os.path.join(path_model_dir, 'Normalization_zonal.mat')\n",
    "normalization = sio.loadmat(normalization_path)\n",
    "X_mean = normalization['X_mean']\n",
    "X_std = normalization['X_std']\n",
    "y_mean = normalization['y_mean']\n",
    "y_std = normalization['y_std']\n",
    "print(\"✅ Normalization data loaded successfully.\")\n",
    "print(X_mean)\n",
    "print(X_std)\n",
    "print(y_mean)\n",
    "print(y_std)\n",
    "# --- 3. Load and Preprocess 4xCO2 Test Data ---\n",
    "print(\"\\nLoading and preprocessing 4xCO2 test data...\")\n",
    "ds_4xCO2_X = xr.open_dataset(file_4xCO2_input)\n",
    "ds_4xCO2_y = xr.open_dataset(file_4xCO2_output)\n",
    "\n",
    "# Extract variables from the correct files\n",
    "TS_4xCO2_raw = ds_4xCO2_X[In_name]\n",
    "TOA_4xCO2_truth = ds_4xCO2_y[Out_name].values\n",
    "lat = ds_4xCO2_X['lat'].values\n",
    "time_4xCO2 = ds_4xCO2_X['year'].values if 'year' in ds_4xCO2_X else ds_4xCO2_X['time'].values\n",
    "\n",
    "# Normalize inputs correctly by adding the channel dimension first\n",
    "TS_4xCO2_norm = (TS_4xCO2_raw.values[..., np.newaxis] - X_mean) / X_std\n",
    "print(\"✅ Test data preprocessed.\")\n",
    "\n",
    "# --- 4. Prediction Loop ---\n",
    "print(\"\\n--- Running Ensemble Predictions for 4xCO2 ---\")\n",
    "n_folds = 5\n",
    "predictions_from_folds = []\n",
    "\n",
    "for fold_no in range(1, n_folds + 1):\n",
    "    K.clear_session(); gc.collect()\n",
    "    \n",
    "    # Use the corrected, direct path to load the model\n",
    "    model_path = os.path.join(path_model_dir, f'model_fold{fold_no}_ens1.h5')\n",
    "    print(f\"    Loading and predicting with model: {model_path}\")\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    pred_4xco2_norm = model.predict(TS_4xCO2_norm)\n",
    "    pred_4xco2_unnorm = pred_4xco2_norm * y_std + y_mean\n",
    "    predictions_from_folds.append(pred_4xco2_unnorm)\n",
    "\n",
    "# Average predictions across the folds\n",
    "Model_pred_4xco2 = np.mean(np.stack(predictions_from_folds), axis=0)\n",
    "print(\"\\n✅ Prediction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60dd36-d92c-4163-b95f-971daad94051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Out-of-Sample Analysis and Visualization (Corrected Plotting Axis)\n",
    "# ==========================================================\n",
    "print(\"\\n--- Starting Out-of-Sample Analysis ---\")\n",
    "\n",
    "# --- Task 1: Calculate Overall Pattern Correlation ---\n",
    "print(\"\\n    Calculating Overall Pattern Correlation...\")\n",
    "truth_flat = TOA_4xCO2_truth.flatten()\n",
    "pred_flat = Model_pred_4xco2.flatten()\n",
    "pattern_r, _ = pearsonr(truth_flat, pred_flat)\n",
    "print(f\"✅ Overall Pattern Correlation (r) = {pattern_r:.4f}\")\n",
    "\n",
    "# --- Task 2: Plot R-squared as a Function of Latitude ---\n",
    "print(\"\\n    Calculating and plotting R-squared per latitude...\")\n",
    "r2_by_latitude = [r2_score(TOA_4xCO2_truth[:, i], Model_pred_4xco2[:, i]) for i in range(len(lat))]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lat, r2_by_latitude, marker='o', linestyle='-')\n",
    "plt.title('Out-of-Sample Performance (R²) by Latitude - 4xCO2', fontsize=16)\n",
    "plt.xlabel('Latitude', fontsize=12)\n",
    "plt.ylabel('R-squared Score', fontsize=12)\n",
    "plt.grid(True, linestyle='--'); plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# --- Task 3: Plot Truth vs. Prediction as a 2D Contour Map ---\n",
    "print(\"\\n    Plotting Truth vs. Prediction as contour maps...\")\n",
    "\n",
    "# This creates a simple numerical axis [0, 1, 2, ...] for plotting\n",
    "time_axis_for_plot = np.arange(TOA_4xCO2_truth.shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6), sharey=True)\n",
    "vmax = np.percentile(np.abs(TOA_4xCO2_truth), 98)\n",
    "vmin = -vmax\n",
    "\n",
    "axes[0].set_title('Ground Truth TOA Zonal Mean', fontsize=16)\n",
    "# Use the new simple time axis for plotting\n",
    "cf1 = axes[0].contourf(time_axis_for_plot, lat, TOA_4xCO2_truth.T, levels=20, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "axes[0].set_xlabel('Time (Model Years)', fontsize=12)\n",
    "axes[0].set_ylabel('Latitude', fontsize=12)\n",
    "\n",
    "axes[1].set_title('Predicted TOA Zonal Mean', fontsize=16)\n",
    "# Use the new simple time axis for plotting here as well\n",
    "cf2 = axes[1].contourf(time_axis_for_plot, lat, Model_pred_4xco2.T, levels=20, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "axes[1].set_xlabel('Time (Model Years)', fontsize=12)\n",
    "\n",
    "fig.colorbar(cf1, ax=axes.ravel().tolist(), shrink=0.8, label='TOA Anomaly (W/m²)')\n",
    "fig.suptitle(\"Out-of-Sample Results - 4xCO2 Scenario\", fontsize=18, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470f59c-3312-4733-9169-81bb557753ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Task 4: Calculate and Compare Global Mean Time Series\n",
    "# =========================================================\n",
    "print(\"\\n--- Calculating and Comparing Weighted Global Means ---\")\n",
    "\n",
    "# --- Step 1: Calculate Latitude Weights ---\n",
    "# To get a true global mean, we must weight each latitude by the cosine\n",
    "# of its angle to account for the smaller grid cell areas near the poles.\n",
    "lat_radians = np.deg2rad(lat)\n",
    "weights = np.cos(lat_radians)\n",
    "# Ensure weights have the correct shape for broadcasting during the average\n",
    "weights = weights[np.newaxis, :]\n",
    "\n",
    "# --- Step 2: Calculate Weighted Average for Truth and Prediction ---\n",
    "# We average over the latitude axis (axis=1) to get a single global\n",
    "# mean value for each time step.\n",
    "global_mean_truth = np.average(TOA_4xCO2_truth, axis=1, weights=weights.flatten())\n",
    "global_mean_pred = np.average(Model_pred_4xco2, axis=1, weights=weights.flatten())\n",
    "\n",
    "print(\"✅ Weighted global means calculated.\")\n",
    "\n",
    "# --- Step 3: Print and Compare the Overall Mean Values ---\n",
    "# This gives a single number summary of the entire time series\n",
    "print(f\"    Overall Mean of Ground Truth: {np.mean(global_mean_truth):.4f} W/m²\")\n",
    "print(f\"    Overall Mean of Prediction:   {np.mean(global_mean_pred):.4f} W/m²\")\n",
    "\n",
    "# --- Step 4: Plot the Global Mean Time Series for Comparison ---\n",
    "print(\"\\n    Plotting global mean time series comparison...\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "time_axis_for_plot = np.arange(global_mean_truth.shape[0])\n",
    "\n",
    "plt.plot(time_axis_for_plot, global_mean_truth, label='Ground Truth', color='black', linewidth=2)\n",
    "plt.plot(time_axis_for_plot, global_mean_pred, label='Model Prediction', color='red', linestyle='--')\n",
    "\n",
    "plt.title('Out-of-Sample: Global Mean TOA Anomaly Time Series', fontsize=16)\n",
    "plt.xlabel('Time (Model Years)', fontsize=12)\n",
    "plt.ylabel('Global Mean Anomaly (W/m²)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025f18b-9ebb-4058-ae42-5357b6e20c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Task 4: Calculate and Compare Global Mean Time Series\n",
    "# =========================================================\n",
    "print(\"\\n--- Calculating and Comparing Weighted Global Means ---\")\n",
    "\n",
    "# --- Step 1: Calculate Latitude Weights ---\n",
    "# To get a true global mean, we must weight each latitude by the cosine\n",
    "# of its angle to account for the smaller grid cell areas near the poles.\n",
    "lat_radians = np.deg2rad(lat)\n",
    "weights = np.cos(lat_radians)\n",
    "# Ensure weights have the correct shape for broadcasting during the average\n",
    "weights = weights[np.newaxis, :]\n",
    "\n",
    "# --- Step 2: Calculate Weighted Average for Truth and Prediction ---\n",
    "# We average over the latitude axis (axis=1) to get a single global\n",
    "# mean value for each time step.\n",
    "global_mean_truth = np.average(TOA_4xCO2_truth, axis=1, weights=weights.flatten())\n",
    "global_mean_pred = np.average(Model_pred_4xco2, axis=1, weights=weights.flatten())\n",
    "\n",
    "print(\"✅ Weighted global means calculated.\")\n",
    "\n",
    "# --- Step 3: Print and Compare the Overall Mean Values ---\n",
    "# This gives a single number summary of the entire time series\n",
    "print(f\"    Overall Mean of Ground Truth: {np.mean(global_mean_truth):.4f} W/m²\")\n",
    "print(f\"    Overall Mean of Prediction:   {np.mean(global_mean_pred):.4f} W/m²\")\n",
    "\n",
    "# --- Step 4: Plot the Global Mean Time Series for Comparison ---\n",
    "print(\"\\n    Plotting global mean time series comparison...\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "time_axis_for_plot = np.arange(global_mean_truth.shape[0])\n",
    "\n",
    "plt.plot(time_axis_for_plot, global_mean_truth, label='Ground Truth', color='black', linewidth=2)\n",
    "plt.plot(time_axis_for_plot, global_mean_pred, label='Model Prediction', color='red', linestyle='--')\n",
    "\n",
    "plt.title('Out-of-Sample: Global Mean TOA Anomaly Time Series', fontsize=16)\n",
    "plt.xlabel('Time (Model Years)', fontsize=12)\n",
    "plt.ylabel('Global Mean Anomaly (W/m²)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbe86a-9ace-4a66-893d-6231e0ecefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# Task 5: Calculate and Plot Climate Feedback Parameter (λ)\n",
    "# =================================================================\n",
    "from scipy.stats import linregress\n",
    "\n",
    "print(\"\\n--- Calculating and Plotting Climate Feedback Parameter (λ) ---\")\n",
    "\n",
    "# --- Step 1: Calculate the X-axis data (Area-Weighted Global Mean TS Anomaly) ---\n",
    "# We already have the latitude weights from the previous task.\n",
    "# First, take the mean across the longitude axis of the raw input data.\n",
    "TS_zonal_mean_truth = np.mean(TS_4xCO2_raw.values, axis=2)\n",
    "\n",
    "# Now, calculate the latitude-weighted average to get the global mean.\n",
    "global_mean_TS_truth = np.average(TS_zonal_mean_truth, axis=1, weights=weights.flatten())\n",
    "\n",
    "# --- Step 2: Set up the side-by-side plots ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "fig.suptitle('Climate Feedback Parameter (λ) - 4xCO2 Out-of-Sample', fontsize=20, weight='bold')\n",
    "\n",
    "# --- Step 3: Plot for the Ground Truth ---\n",
    "ax1 = axes[0]\n",
    "# Perform linear regression to find the slope (lambda)\n",
    "slope_truth, intercept_truth, r_value_truth, _, _ = linregress(global_mean_TS_truth, global_mean_truth)\n",
    "lambda_truth = slope_truth\n",
    "r2_truth = r_value_truth**2\n",
    "\n",
    "# Scatter plot\n",
    "ax1.scatter(global_mean_TS_truth, global_mean_truth, alpha=0.6, label='Yearly Data (Ground Truth)')\n",
    "# Best-fit line\n",
    "fit_line_truth = slope_truth * global_mean_TS_truth + intercept_truth\n",
    "ax1.plot(global_mean_TS_truth, fit_line_truth, color='red', linestyle='--', label='Linear Best Fit')\n",
    "\n",
    "# Add text box with results\n",
    "text_truth = (f'λ = {lambda_truth:.3f} W/m²/K\\n'\n",
    "              f'$R^2$ = {r2_truth:.3f}')\n",
    "ax1.text(0.05, 0.95, text_truth, transform=ax1.transAxes, fontsize=14,\n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "ax1.set_title('Ground Truth Data', fontsize=16)\n",
    "ax1.set_xlabel('Area-Weighted Global Mean TS Anomaly (K)', fontsize=12)\n",
    "ax1.set_ylabel('Global Mean TOA Anomaly (W/m²)', fontsize=12)\n",
    "ax1.grid(True, linestyle=':')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "# --- Step 4: Plot for the Model Prediction ---\n",
    "ax2 = axes[1]\n",
    "# Perform linear regression\n",
    "slope_pred, intercept_pred, r_value_pred, _, _ = linregress(global_mean_TS_truth, global_mean_pred)\n",
    "lambda_pred = slope_pred\n",
    "r2_pred = r_value_pred**2\n",
    "\n",
    "# Scatter plot\n",
    "ax2.scatter(global_mean_TS_truth, global_mean_pred, alpha=0.6, label='Yearly Data (Model Prediction)')\n",
    "# Best-fit line\n",
    "fit_line_pred = slope_pred * global_mean_TS_truth + intercept_pred\n",
    "ax2.plot(global_mean_TS_truth, fit_line_pred, color='red', linestyle='--', label='Linear Best Fit')\n",
    "\n",
    "# Add text box with results\n",
    "text_pred = (f'λ = {lambda_pred:.3f} W/m²/K\\n'\n",
    "             f'$R^2$ = {r2_pred:.3f}')\n",
    "ax2.text(0.05, 0.95, text_pred, transform=ax2.transAxes, fontsize=14,\n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "ax2.set_title('Model Prediction', fontsize=16)\n",
    "ax2.set_xlabel('Area-Weighted Global Mean TS Anomaly (K)', fontsize=12)\n",
    "# No Y-label needed as it's shared with ax1\n",
    "ax2.grid(True, linestyle=':')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make room for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a236f7b-12bc-4b9b-9417-fee50b11ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# NEW ANALYSIS: Global Mean of Zonal-Mean Prediction vs. Truth\n",
    "# ==========================================================\n",
    "print(\"\\n--- Starting new analysis: Comparing the area-weighted global mean ---\")\n",
    "\n",
    "# --- 1. Helper Function for Area-Weighted Mean ---\n",
    "# This function correctly calculates the global mean from zonal-mean [time, lat] data.\n",
    "def calculate_area_weighted_global_mean_zonal(data_2d, lat_coords):\n",
    "    \"\"\"\n",
    "    Calculates the area-weighted global mean from a [time, lat] array.\n",
    "    \"\"\"\n",
    "    # The weights for each latitude band are proportional to the cosine of the latitude.\n",
    "    weights = np.cos(np.deg2rad(lat_coords))\n",
    "    # np.average calculates the weighted average over the latitude axis (axis=1).\n",
    "    global_mean_timeseries = np.average(data_2d, axis=1, weights=weights)\n",
    "    return global_mean_timeseries\n",
    "\n",
    "# --- 2. Calculate the Global Mean Time Series ---\n",
    "# This assumes 'TOA_4xCO2_truth' and 'Model_pred_4xco2' are in memory from the previous cell.\n",
    "# It also assumes 'lat' (your latitude coordinate array) is in memory.\n",
    "\n",
    "print(\"    Calculating global mean for both truth and prediction...\")\n",
    "global_mean_truth = calculate_area_weighted_global_mean_zonal(TOA_4xCO2_truth, lat)\n",
    "global_mean_pred = calculate_area_weighted_global_mean_zonal(Model_pred_4xco2, lat)\n",
    "\n",
    "# --- 3. Plot the Comparison Graph ---\n",
    "print(\"    Plotting the global mean comparison graph...\")\n",
    "\n",
    "# Calculate the R-squared score for the global mean time series\n",
    "r2_global_mean = r2_score(global_mean_truth, global_mean_pred)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(time_4xCO2, global_mean_truth, label=\"Truth (Global Mean)\", color=\"k\", linewidth=2.5)\n",
    "ax.plot(time_4xCO2, global_mean_pred, label=\"Prediction (Global Mean)\", color=\"C3\", linestyle='--')\n",
    "\n",
    "# Add R-squared annotation\n",
    "ax.text(0.02, 0.95, f\"$R^2$ = {r2_global_mean:.3f}\", transform=ax.transAxes,\n",
    "        fontsize=16, bbox=dict(facecolor=\"white\", edgecolor=\"black\", alpha=0.7))\n",
    "\n",
    "# Style the plot\n",
    "ax.set_xlabel(\"Time (Year)\", fontsize=16)\n",
    "ax.set_ylabel(\"Global Mean TOA Anomaly (W/m²)\", fontsize=16)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "ax.set_title(\"Model Performance on Global Mean (from Zonal-Mean Prediction)\", fontsize=18, pad=15)\n",
    "ax.legend(fontsize=14, loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf210)",
   "language": "python",
   "name": "tf210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
