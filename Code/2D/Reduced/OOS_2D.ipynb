{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf742dd-11ae-43ac-8ae9-c1aa4c02511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 16:31:58.026375: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-24 16:31:58.216031: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-24 16:31:58.254650: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up for Zonal-Mean Out-of-Sample Test (PCA version) ---\n",
      "Loading normalization data...\n",
      "✅ Normalization data loaded successfully.\n",
      "\n",
      "Loading and preprocessing 4xCO2 test data...\n",
      "✅ Test data preprocessed.\n",
      "\n",
      "--- Running Ensemble Predictions for 4xCO2 ---\n",
      "    Loading model: /ocean/projects/ees250004p/ezhu3/data/CESM2/trained_model_2D_PCA/model_fold1_ens1.h5\n",
      "    Loading PCA transformer: /ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model_2D_PCA/NeuralNet/CNN_Neur32x32_BS32_5foldCV_Reg0Drop0.25_gelu+PReLU/TOA_anom/pca_y_fold1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 16:32:02.952013: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-24 16:32:03.984315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 223 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "2025-07-24 16:32:14.742291: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 216.00MiB (rounded to 226492416)requested by op model/conv2d/Conv2D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-07-24 16:32:14.742395: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2025-07-24 16:32:14.742415: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 26, Chunks in use: 26. 6.5KiB allocated for chunks. 6.5KiB in use in bin. 632B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742421: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.2KiB client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742426: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.1KiB client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742431: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742435: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 4.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742440: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 9.5KiB allocated for chunks. 9.5KiB in use in bin. 5.3KiB client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742444: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742448: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 53.8KiB allocated for chunks. 53.8KiB in use in bin. 36.0KiB client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742452: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742456: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742459: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742462: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742466: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742469: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742474: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 13.50MiB allocated for chunks. 13.50MiB in use in bin. 13.50MiB client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742477: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742482: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 31.64MiB allocated for chunks. 31.64MiB in use in bin. 31.64MiB client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742485: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742489: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742495: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 178.22MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742499: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-24 16:32:14.742783: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 216.00MiB was 128.00MiB, Chunk State: \n",
      "2025-07-24 16:32:14.742797: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 178.22MiB | Requested Size: 0B | in_use: 0 | bin_num: 19, prev:   Size: 6.75MiB | Requested Size: 6.75MiB | in_use: 1 | bin_num: -1\n",
      "2025-07-24 16:32:14.742801: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 234291200\n",
      "2025-07-24 16:32:14.742812: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000000 of size 1280 next 1\n",
      "2025-07-24 16:32:14.742816: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000500 of size 256 next 2\n",
      "2025-07-24 16:32:14.742819: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000600 of size 256 next 3\n",
      "2025-07-24 16:32:14.742822: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000700 of size 256 next 5\n",
      "2025-07-24 16:32:14.742825: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000800 of size 256 next 6\n",
      "2025-07-24 16:32:14.742828: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000900 of size 256 next 4\n",
      "2025-07-24 16:32:14.742832: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000a00 of size 256 next 7\n",
      "2025-07-24 16:32:14.742835: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000b00 of size 256 next 12\n",
      "2025-07-24 16:32:14.742838: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000c00 of size 256 next 10\n",
      "2025-07-24 16:32:14.742841: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000d00 of size 256 next 11\n",
      "2025-07-24 16:32:14.742844: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000e00 of size 256 next 17\n",
      "2025-07-24 16:32:14.742847: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2000f00 of size 256 next 15\n",
      "2025-07-24 16:32:14.742850: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001000 of size 256 next 16\n",
      "2025-07-24 16:32:14.742853: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001100 of size 256 next 20\n",
      "2025-07-24 16:32:14.742856: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001200 of size 256 next 22\n",
      "2025-07-24 16:32:14.742859: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001300 of size 256 next 8\n",
      "2025-07-24 16:32:14.742862: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001400 of size 256 next 27\n",
      "2025-07-24 16:32:14.742866: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001500 of size 512 next 19\n",
      "2025-07-24 16:32:14.742869: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001700 of size 256 next 31\n",
      "2025-07-24 16:32:14.742872: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001800 of size 256 next 9\n",
      "2025-07-24 16:32:14.742875: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001900 of size 256 next 21\n",
      "2025-07-24 16:32:14.742878: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001a00 of size 256 next 23\n",
      "2025-07-24 16:32:14.742881: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001b00 of size 256 next 32\n",
      "2025-07-24 16:32:14.742884: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001c00 of size 256 next 33\n",
      "2025-07-24 16:32:14.742889: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001d00 of size 256 next 34\n",
      "2025-07-24 16:32:14.742892: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001e00 of size 256 next 35\n",
      "2025-07-24 16:32:14.742895: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2001f00 of size 256 next 25\n",
      "2025-07-24 16:32:14.742898: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2002000 of size 256 next 28\n",
      "2025-07-24 16:32:14.742901: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2002100 of size 1280 next 26\n",
      "2025-07-24 16:32:14.742904: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2002600 of size 9728 next 29\n",
      "2025-07-24 16:32:14.742908: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2004c00 of size 768 next 18\n",
      "2025-07-24 16:32:14.742911: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 1505c2004f00 of size 4864 next 30\n",
      "2025-07-24 16:32:14.742914: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2006200 of size 55040 next 14\n",
      "2025-07-24 16:32:14.742917: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c2013900 of size 7077888 next 13\n",
      "2025-07-24 16:32:14.742920: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c26d3900 of size 33177600 next 24\n",
      "2025-07-24 16:32:14.742924: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 1505c4677900 of size 7077888 next 36\n",
      "2025-07-24 16:32:14.742927: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 1505c4d37900 of size 186877696 next 18446744073709551615\n",
      "2025-07-24 16:32:14.742930: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2025-07-24 16:32:14.742935: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 26 Chunks of size 256 totalling 6.5KiB\n",
      "2025-07-24 16:32:14.742939: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 512 totalling 512B\n",
      "2025-07-24 16:32:14.742942: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 768 totalling 768B\n",
      "2025-07-24 16:32:14.742945: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2025-07-24 16:32:14.742951: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 9728 totalling 9.5KiB\n",
      "2025-07-24 16:32:14.742955: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 55040 totalling 53.8KiB\n",
      "2025-07-24 16:32:14.742959: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 7077888 totalling 13.50MiB\n",
      "2025-07-24 16:32:14.742962: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 33177600 totalling 31.64MiB\n",
      "2025-07-24 16:32:14.742966: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 45.21MiB\n",
      "2025-07-24 16:32:14.742969: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 234291200 memory_limit_: 234291200 available bytes: 0 curr_region_allocation_bytes_: 468582400\n",
      "2025-07-24 16:32:14.742979: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                       234291200\n",
      "InUse:                        47408640\n",
      "MaxInUse:                     47408640\n",
      "NumAllocs:                          72\n",
      "MaxAllocSize:                 33177600\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-07-24 16:32:14.742987: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *********************_______________________________________________________________________________\n",
      "2025-07-24 16:32:14.743500: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at conv_ops.cc:686 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,192,288] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/tmp/ipykernel_34548/4228956120.py\", line 88, in <module>\n      pred_4xco2_pca = model.predict(TS_4xCO2_norm)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nOOM when allocating tensor with shape[32,32,192,288] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_352]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m pca_y \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(pca_path)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# 1. Predict the PCA components\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m pred_4xco2_pca \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTS_4xCO2_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_4xco2_pca\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# 2. Inverse transform from PCA space to normalized data space\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/tmp/ipykernel_34548/4228956120.py\", line 88, in <module>\n      pred_4xco2_pca = model.predict(TS_4xCO2_norm)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nOOM when allocating tensor with shape[32,32,192,288] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_352]"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# FINAL OUT-OF-SAMPLE TEST SCRIPT FOR 2D ZONAL-MEAN MODELS (with PCA)\n",
    "# ===================================================================\n",
    "# This script is specifically designed to test models that were\n",
    "# trained by applying PCA to the target variable (y).\n",
    "# It correctly loads the saved PCA transformer for each fold.\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import joblib # <-- Required to load the PCA model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from keras.models import load_model\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# --- 1. Configuration: Set Correct Paths for the PCA Model Run ---\n",
    "print(\"--- Setting up for Zonal-Mean Out-of-Sample Test (PCA version) ---\")\n",
    "\n",
    "# **FIX**: Define separate paths for models vs. pca/log files\n",
    "# path_model_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM2/trained_model_2D_PCA'\n",
    "# path_results_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM2/trained_model_2D_PCA/NeuralNet/CNN_Neur32x32_BS32_5foldCV_Reg0Drop0.25_gelu+PReLU/TOA_anom'\n",
    "\n",
    "#C1:\n",
    "path_model_dir = \"/ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model_2D_PCA\"\n",
    "path_results_dir = \"/ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model_2D_PCA/NeuralNet/CNN_Neur32x32_BS32_5foldCV_Reg0Drop0.25_gelu+PReLU/TOA_anom\"\n",
    "\n",
    "\n",
    "# Define variable names for your test files\n",
    "In_name = \"TS\"\n",
    "Out_name = \"TOA_anom\"\n",
    "\n",
    "# Define paths to your out-of-sample 4xCO2 test files\n",
    "# file_4xCO2_input = \"/ocean/projects/ees250004p/ezhu3/data/CESM2/test/test.CESM2-4xCO2.ANN.nc\"\n",
    "# file_4xCO2_output = \"/ocean/projects/ees250004p/ezhu3/data/CESM2/test/test.CESM2-4xCO2.zmean.ANN.nc\"\n",
    "file_4xCO2_input = \"/ocean/projects/ees250004p/ezhu3/data/CESM1/test/test.4xCO2.ANN.new.nc\"\n",
    "file_4xCO2_output = \"/ocean/projects/ees250004p/ezhu3/data/CESM1/test/test.4xCO2.zmean.ANN.new.nc\"\n",
    "\n",
    "\n",
    "# --- 2. Load Normalization Data from the Training Run ---\n",
    "print(\"Loading normalization data...\")\n",
    "# **FIX**: Normalization file is in the main model directory\n",
    "normalization_path = os.path.join(path_model_dir, 'Normalization_zonal.mat')\n",
    "normalization = sio.loadmat(normalization_path)\n",
    "X_mean = normalization['X_mean']\n",
    "X_std = normalization['X_std']\n",
    "y_mean = normalization['y_mean']\n",
    "y_std = normalization['y_std']\n",
    "print(\"✅ Normalization data loaded successfully.\")\n",
    "\n",
    "# --- 3. Load and Preprocess 4xCO2 Test Data ---\n",
    "print(\"\\nLoading and preprocessing 4xCO2 test data...\")\n",
    "ds_4xCO2_X = xr.open_dataset(file_4xCO2_input)\n",
    "ds_4xCO2_y = xr.open_dataset(file_4xCO2_output)\n",
    "\n",
    "TS_4xCO2_raw = ds_4xCO2_X[In_name]\n",
    "TOA_4xCO2_truth = ds_4xCO2_y[Out_name].values\n",
    "lat = ds_4xCO2_X['lat'].values\n",
    "time_4xCO2 = ds_4xCO2_X['year'].values if 'year' in ds_4xCO2_X else ds_4xCO2_X['time'].values\n",
    "\n",
    "TS_4xCO2_norm = (TS_4xCO2_raw.values[..., np.newaxis] - X_mean) / X_std\n",
    "print(\"✅ Test data preprocessed.\")\n",
    "\n",
    "# --- 4. Prediction Loop with PCA Inverse Transform ---\n",
    "print(\"\\n--- Running Ensemble Predictions for 4xCO2 ---\")\n",
    "n_folds = 5\n",
    "predictions_from_folds = []\n",
    "\n",
    "for fold_no in range(1, n_folds + 1):\n",
    "    K.clear_session(); gc.collect()\n",
    "    \n",
    "    # **FIX**: Construct the full path to the .h5 file and the .pkl file\n",
    "    model_path = os.path.join(path_model_dir, f'model_fold{fold_no}_ens1.h5')\n",
    "    pca_path = os.path.join(path_results_dir, f'pca_y_fold{fold_no}.pkl')\n",
    "    \n",
    "    print(f\"    Loading model: {model_path}\")\n",
    "    print(f\"    Loading PCA transformer: {pca_path}\")\n",
    "    \n",
    "    # Load the trained model from its .h5 file path and the PCA transformer\n",
    "    model = load_model(model_path, compile=False)\n",
    "    pca_y = joblib.load(pca_path)\n",
    "    \n",
    "    # 1. Predict the PCA components\n",
    "    pred_4xco2_pca = model.predict(TS_4xCO2_norm)\n",
    "    print(pred_4xco2_pca.shape)\n",
    "    \n",
    "    # 2. Inverse transform from PCA space to normalized data space\n",
    "    pred_4xco2_norm = pca_y.inverse_transform(pred_4xco2_pca)\n",
    "    \n",
    "    # 3. Un-normalize the data\n",
    "    pred_4xco2_unnorm = pred_4xco2_norm * y_std + y_mean\n",
    "    \n",
    "    predictions_from_folds.append(pred_4xco2_unnorm)\n",
    "\n",
    "# Average predictions across the folds\n",
    "Model_pred_4xco2 = np.mean(np.stack(predictions_from_folds), axis=0)\n",
    "print(\"\\n✅ Prediction complete.\")\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# Out-of-Sample Analysis and Visualization (No changes needed here)\n",
    "# =================================================================\n",
    "print(\"\\n--- Starting Out-of-Sample Analysis ---\")\n",
    "\n",
    "# --- Task 1: Calculate Overall Pattern Correlation ---\n",
    "print(\"\\n    Calculating Overall Pattern Correlation...\")\n",
    "truth_flat = TOA_4xCO2_truth.flatten()\n",
    "pred_flat = Model_pred_4xco2.flatten()\n",
    "pattern_r, _ = pearsonr(truth_flat, pred_flat)\n",
    "print(f\"✅ Overall Pattern Correlation (r) = {pattern_r:.4f}\")\n",
    "\n",
    "# --- Task 2: Plot R-squared as a Function of Latitude ---\n",
    "print(\"\\n    Calculating and plotting R-squared per latitude...\")\n",
    "r2_by_latitude = [r2_score(TOA_4xCO2_truth[:, i], Model_pred_4xco2[:, i]) for i in range(len(lat))]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lat, r2_by_latitude, marker='o', linestyle='-')\n",
    "plt.title('Out-of-Sample Performance (R²) by Latitude - 4xCO2', fontsize=16)\n",
    "plt.xlabel('Latitude', fontsize=12)\n",
    "plt.ylabel('R-squared Score', fontsize=12)\n",
    "plt.grid(True, linestyle='--'); plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# --- Task 3: Plot Truth vs. Prediction as a 2D Contour Map ---\n",
    "print(\"\\n    Plotting Truth vs. Prediction as contour maps...\")\n",
    "\n",
    "time_axis_for_plot = np.arange(TOA_4xCO2_truth.shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6), sharey=True)\n",
    "vmax = np.percentile(np.abs(TOA_4xCO2_truth), 98)\n",
    "vmin = -vmax\n",
    "\n",
    "axes[0].set_title('Ground Truth TOA Zonal Mean', fontsize=16)\n",
    "cf1 = axes[0].contourf(time_axis_for_plot, lat, TOA_4xCO2_truth.T, levels=20, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "axes[0].set_xlabel('Time (Model Years)', fontsize=12)\n",
    "axes[0].set_ylabel('Latitude', fontsize=12)\n",
    "\n",
    "axes[1].set_title('Predicted TOA Zonal Mean', fontsize=16)\n",
    "cf2 = axes[1].contourf(time_axis_for_plot, lat, Model_pred_4xco2.T, levels=20, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "axes[1].set_xlabel('Time (Model Years)', fontsize=12)\n",
    "\n",
    "fig.colorbar(cf1, ax=axes.ravel().tolist(), shrink=0.8, label='TOA Anomaly (W/m²)')\n",
    "fig.suptitle(\"Out-of-Sample Results - 4xCO2 Scenario\", fontsize=18, fontweight='bold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "tf210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
