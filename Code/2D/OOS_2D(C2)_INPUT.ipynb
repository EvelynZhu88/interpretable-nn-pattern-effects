{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbba3047-f803-4acb-a677-8feba2a8497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 19:18:58.554729: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 19:18:59.863493: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-30 19:19:00.137531: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up for Zonal-Mean Out-of-Sample Test ---\n",
      "Loading normalization data...\n",
      "✅ Normalization data loaded successfully.\n",
      "[[[222.94443]\n",
      "  [222.94443]\n",
      "  [222.94443]\n",
      "  ...\n",
      "  [222.94443]\n",
      "  [222.94443]\n",
      "  [222.94443]]\n",
      "\n",
      " [[223.51381]\n",
      "  [223.47977]\n",
      "  [223.34406]\n",
      "  ...\n",
      "  [223.54082]\n",
      "  [223.53523]\n",
      "  [223.52567]]\n",
      "\n",
      " [[224.13083]\n",
      "  [224.09398]\n",
      "  [224.07494]\n",
      "  ...\n",
      "  [224.33713]\n",
      "  [224.29172]\n",
      "  [224.22809]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255.92625]\n",
      "  [255.94229]\n",
      "  [255.95798]\n",
      "  ...\n",
      "  [255.88461]\n",
      "  [255.89777]\n",
      "  [255.91098]]\n",
      "\n",
      " [[255.81615]\n",
      "  [255.82231]\n",
      "  [255.82944]\n",
      "  ...\n",
      "  [255.79529]\n",
      "  [255.80214]\n",
      "  [255.80928]]\n",
      "\n",
      " [[255.6866 ]\n",
      "  [255.68732]\n",
      "  [255.68805]\n",
      "  ...\n",
      "  [255.68419]\n",
      "  [255.6851 ]\n",
      "  [255.68585]]]\n",
      "[[[0.70500857]\n",
      "  [0.70500576]\n",
      "  [0.70500827]\n",
      "  ...\n",
      "  [0.70500445]\n",
      "  [0.7050062 ]\n",
      "  [0.7050094 ]]\n",
      "\n",
      " [[0.74037784]\n",
      "  [0.7402208 ]\n",
      "  [0.74013007]\n",
      "  ...\n",
      "  [0.7406546 ]\n",
      "  [0.74058586]\n",
      "  [0.74052685]]\n",
      "\n",
      " [[0.76330787]\n",
      "  [0.7628692 ]\n",
      "  [0.76243496]\n",
      "  ...\n",
      "  [0.7645274 ]\n",
      "  [0.7641407 ]\n",
      "  [0.76372313]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.0075827 ]\n",
      "  [1.009736  ]\n",
      "  [1.0118273 ]\n",
      "  ...\n",
      "  [1.0020808 ]\n",
      "  [1.0038892 ]\n",
      "  [1.0056243 ]]\n",
      "\n",
      " [[0.9827783 ]\n",
      "  [0.98358   ]\n",
      "  [0.98441947]\n",
      "  ...\n",
      "  [0.9801285 ]\n",
      "  [0.9810324 ]\n",
      "  [0.9819265 ]]\n",
      "\n",
      " [[0.9659744 ]\n",
      "  [0.9660457 ]\n",
      "  [0.96610993]\n",
      "  ...\n",
      "  [0.96571904]\n",
      "  [0.9658127 ]\n",
      "  [0.96589845]]]\n",
      "[[ 1.02481841e-04  1.41601558e-05  1.76136018e-04 -1.04003906e-04\n",
      "  -2.63862603e-05 -4.16030889e-05  9.58557139e-05  3.79066478e-05\n",
      "   8.85009740e-07  1.53160090e-05  1.76681526e-04  1.29318241e-05\n",
      "   5.76591483e-05 -2.43339546e-05  7.14607231e-05 -3.27911366e-05\n",
      "   1.41868595e-05  5.87425238e-05  5.98297120e-05 -2.18391415e-05\n",
      "   2.06604000e-05  6.82716345e-05 -4.42543023e-05  3.13072196e-05\n",
      "  -2.74276736e-05 -1.42776495e-04 -3.19557184e-05  4.82254036e-05\n",
      "   7.70568874e-07 -6.42166124e-05  2.31819158e-05  8.71429438e-05\n",
      "  -8.00552370e-05  2.87628177e-06  1.85146328e-05  2.25391395e-05\n",
      "   9.67216511e-06  2.79350279e-05 -8.78715491e-06  3.14865101e-05\n",
      "  -9.16480985e-06  1.59320825e-05 -1.68666847e-05  3.80210877e-05\n",
      "  -2.77614599e-05 -1.29508971e-05  8.74137913e-06  1.81655887e-05\n",
      "   1.91211711e-06  2.53973012e-05 -2.01988223e-06  3.45573426e-05\n",
      "   3.11622607e-05  1.94597251e-05 -1.25913621e-05 -2.85196302e-06\n",
      "  -4.19425942e-06 -4.12821777e-07 -1.96218494e-07  5.90205218e-07\n",
      "   1.40666955e-07 -1.30224225e-06  1.81245809e-06 -1.60813324e-05\n",
      "  -1.74827583e-05  2.09312439e-05  8.64505728e-06 -5.08022322e-06\n",
      "   1.01842879e-05  2.53963481e-06  7.27653514e-07 -4.38022607e-06\n",
      "   1.45244599e-06 -1.41639712e-05 -2.71606450e-06 -3.60012064e-06\n",
      "   1.03588109e-05 -2.79769902e-05  4.15058130e-05 -5.75065633e-06\n",
      "  -3.21197513e-06 -2.89649961e-05  7.62996642e-05 -9.93347203e-06\n",
      "  -2.39028923e-05 -1.41162873e-05 -2.04029075e-05  9.30023180e-06\n",
      "  -1.29318232e-06 -3.06663496e-05 -3.27930466e-05  8.37707557e-06\n",
      "   4.18472300e-05 -2.80036929e-05  1.36756898e-05 -3.90663154e-05\n",
      "  -1.47514347e-05  1.10515597e-04 -3.47328169e-05 -8.93783545e-06\n",
      "   4.55875379e-05  3.48625181e-05 -1.33171079e-05  2.33364099e-05\n",
      "   3.78990171e-06  9.74082923e-06 -9.75036619e-06 -3.63197323e-05\n",
      "   3.69453437e-06 -1.67522430e-05  2.48546603e-05  1.38320920e-05\n",
      "  -3.25317378e-05  1.05285644e-05  1.46064758e-05  6.58416729e-06\n",
      "  -2.58531563e-05  3.47290043e-05 -4.65650555e-05 -6.99806196e-06\n",
      "  -2.77109139e-05 -2.21233367e-05  4.60720048e-06 -1.24311446e-05\n",
      "   6.46018998e-06 -7.71236409e-06  8.12673534e-06 -1.59740443e-06\n",
      "  -3.06844709e-06 -7.70759561e-06  6.97278983e-06  8.07833658e-06\n",
      "   6.27040845e-06 -1.01208684e-06  3.54933741e-06 -2.26771840e-06\n",
      "  -2.40206717e-08 -9.44733642e-07 -1.85966485e-07  8.75854494e-06\n",
      "  -1.43527984e-07  2.87008279e-05 -6.43062594e-06  1.94501881e-05\n",
      "  -1.94892891e-05  5.44261911e-06 -4.31823719e-06  4.62780008e-05\n",
      "   1.23729706e-05 -2.17914585e-05  2.93731688e-07  5.76210005e-06\n",
      "  -7.05719003e-07  2.65426643e-05  1.25370025e-05  9.12761680e-05\n",
      "  -4.70542909e-06  9.96398921e-06 -4.59213261e-05 -5.67131028e-05\n",
      "  -1.15146635e-04  3.52554307e-05 -6.45980836e-05 -6.37626654e-05\n",
      "   4.85763558e-05  7.19451918e-06  1.42776495e-04 -3.56788623e-05\n",
      "  -5.49621582e-05 -5.77239989e-05  1.60980221e-06 -3.35388177e-05\n",
      "   1.34983056e-04 -1.04091647e-04 -8.01010101e-05 -6.36100740e-05\n",
      "   6.27937334e-05 -8.75930782e-05 -1.71295163e-04  1.49967193e-04\n",
      "   3.24745160e-05 -6.22100852e-05 -7.50350955e-06  1.29699711e-05\n",
      "  -4.50134257e-06  1.61972042e-04  5.37757878e-05  6.82678219e-05\n",
      "  -1.04259489e-04 -2.22778326e-05  1.26602172e-04  7.11250323e-05]]\n",
      "[[1.1908861  1.1703049  1.1202638  1.0629339  1.0172046  0.9930116\n",
      "  0.981361   0.964592   0.950623   0.9364285  0.92162734 0.9016738\n",
      "  0.8859335  0.96001035 1.0527908  1.04716    1.0332865  1.0378579\n",
      "  0.999709   0.93430024 0.93132716 1.0137584  1.1374654  1.1288849\n",
      "  1.1514851  1.2876607  1.4486275  1.4092035  1.3140324  1.2392188\n",
      "  1.1444274  1.0879781  1.0682241  1.0477573  1.0136533  0.9796961\n",
      "  0.97612983 0.99212384 1.0216887  1.0526297  1.0813006  1.1164253\n",
      "  1.1526071  1.1816671  1.2065198  1.2135463  1.2049475  1.1766922\n",
      "  1.1392503  1.1018404  1.0700076  1.0584174  1.0635347  1.0826921\n",
      "  1.1079438  1.1234088  1.1363395  1.1405363  1.141826   1.1224829\n",
      "  1.0888541  1.0458575  1.0125406  0.9906523  0.98579663 0.979395\n",
      "  0.9810889  0.9815201  0.9854952  0.99402726 1.0049293  1.0182068\n",
      "  1.0488755  1.0925137  1.141603   1.1989318  1.2661486  1.3140082\n",
      "  1.3370222  1.3449683  1.3313879  1.3077971  1.2939503  1.2928842\n",
      "  1.2836075  1.256644   1.1975064  1.1339375  1.046427   0.99247193\n",
      "  0.98709077 1.0122788  1.1136461  1.209023   1.3477013  1.4860644\n",
      "  1.5555027  1.5536956  1.5116719  1.5138106  1.579254   1.7354126\n",
      "  1.8776183  1.8584403  1.7104572  1.5345204  1.4446322  1.4429908\n",
      "  1.4421122  1.4365951  1.4310868  1.3946226  1.3218278  1.2405659\n",
      "  1.1455464  1.0527068  0.9703265  0.91903377 0.89651924 0.87862986\n",
      "  0.86244017 0.8504029  0.8405591  0.83474463 0.83699024 0.8346227\n",
      "  0.83541876 0.84168565 0.8477213  0.8609551  0.8810363  0.8802153\n",
      "  0.87117946 0.83890885 0.796182   0.7815402  0.7822322  0.78328854\n",
      "  0.78475446 0.7780989  0.7702172  0.7821052  0.7830036  0.7885807\n",
      "  0.7914651  0.8027496  0.81737196 0.8028551  0.78428453 0.7675443\n",
      "  0.7528726  0.7430172  0.74155456 0.7460755  0.755592   0.7637623\n",
      "  0.77839065 0.79725224 0.813924   0.823009   0.8353693  0.86914915\n",
      "  0.88951397 0.89594746 0.91166323 0.9281012  0.96215206 0.9773177\n",
      "  0.98102206 0.9953645  1.0656226  1.1194993  1.1280179  1.1231178\n",
      "  1.1205136  1.1068228  1.0865864  1.0996418  1.1182922  1.1586276\n",
      "  1.2131782  1.2422943  1.2762554  1.3555279  1.431204   1.4993526\n",
      "  1.556763   1.6068789  1.654959   1.7049515  1.7558464  1.8101698 ]]\n",
      "\n",
      "Loading and preprocessing 4xCO2 test data...\n",
      "✅ Test data preprocessed.\n",
      "\n",
      "--- Running Ensemble Predictions for 4xCO2 ---\n",
      "    Loading and predicting with model: /ocean/projects/ees250004p/ezhu3/data/CESM2/trained_model_2D_changedLRandKS/model_fold1_ens1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 19:19:05.706610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 19:19:06.668804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 223 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "2025-07-30 19:19:17.003749: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 512B (rounded to 512)requested by op Fill\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-07-30 19:19:17.003784: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2025-07-30 19:19:17.003970: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 27, Chunks in use: 27. 6.8KiB allocated for chunks. 6.8KiB in use in bin. 864B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.003977: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 10, Chunks in use: 10. 5.5KiB allocated for chunks. 5.5KiB in use in bin. 5.5KiB client-requested in use in bin.\n",
      "2025-07-30 19:19:17.003981: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 4, Chunks in use: 4. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 4.4KiB client-requested in use in bin.\n",
      "2025-07-30 19:19:17.003986: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.003990: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.003994: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.003998: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004004: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 3, Chunks in use: 3. 156.2KiB allocated for chunks. 156.2KiB in use in bin. 108.0KiB client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004009: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 4, Chunks in use: 4. 382.2KiB allocated for chunks. 382.2KiB in use in bin. 320.0KiB client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004013: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004017: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004021: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004024: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004028: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004032: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004036: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004039: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004045: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 2. 114.92MiB allocated for chunks. 114.92MiB in use in bin. 108.00MiB client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004050: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 107.97MiB allocated for chunks. 107.97MiB in use in bin. 54.00MiB client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004056: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004060: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-07-30 19:19:17.004234: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 512B was 512B, Chunk State: \n",
      "2025-07-30 19:19:17.004239: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 234291200\n",
      "2025-07-30 19:19:17.004614: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000000 of size 1280 next 1\n",
      "2025-07-30 19:19:17.004620: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000500 of size 256 next 2\n",
      "2025-07-30 19:19:17.004623: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000600 of size 256 next 3\n",
      "2025-07-30 19:19:17.004626: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000700 of size 256 next 5\n",
      "2025-07-30 19:19:17.004630: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000800 of size 256 next 6\n",
      "2025-07-30 19:19:17.004633: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000900 of size 256 next 4\n",
      "2025-07-30 19:19:17.004636: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000a00 of size 256 next 7\n",
      "2025-07-30 19:19:17.004639: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000b00 of size 256 next 12\n",
      "2025-07-30 19:19:17.004642: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000c00 of size 256 next 10\n",
      "2025-07-30 19:19:17.004645: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000d00 of size 256 next 11\n",
      "2025-07-30 19:19:17.004649: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86000e00 of size 512 next 17\n",
      "2025-07-30 19:19:17.004652: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86001000 of size 512 next 15\n",
      "2025-07-30 19:19:17.004655: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86001200 of size 256 next 16\n",
      "2025-07-30 19:19:17.004658: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86001300 of size 256 next 8\n",
      "2025-07-30 19:19:17.004662: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d86001400 of size 56623104 next 40\n",
      "2025-07-30 19:19:17.004665: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d89601400 of size 512 next 43\n",
      "2025-07-30 19:19:17.004668: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d89601600 of size 512 next 44\n",
      "2025-07-30 19:19:17.004671: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d89601800 of size 98304 next 45\n",
      "2025-07-30 19:19:17.004675: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d89619800 of size 768 next 46\n",
      "2025-07-30 19:19:17.004678: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d89619b00 of size 1280 next 47\n",
      "2025-07-30 19:19:17.004681: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d8961a000 of size 256 next 48\n",
      "2025-07-30 19:19:17.004685: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d8961a100 of size 36864 next 49\n",
      "2025-07-30 19:19:17.004688: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d89623100 of size 256 next 50\n",
      "2025-07-30 19:19:17.004691: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d89623200 of size 113220352 next 20\n",
      "2025-07-30 19:19:17.004694: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021cd00 of size 256 next 22\n",
      "2025-07-30 19:19:17.004697: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021ce00 of size 256 next 25\n",
      "2025-07-30 19:19:17.004702: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021cf00 of size 256 next 13\n",
      "2025-07-30 19:19:17.004705: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021d000 of size 256 next 31\n",
      "2025-07-30 19:19:17.004708: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021d100 of size 256 next 28\n",
      "2025-07-30 19:19:17.004711: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021d200 of size 256 next 26\n",
      "2025-07-30 19:19:17.004714: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021d300 of size 1280 next 27\n",
      "2025-07-30 19:19:17.004717: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021d800 of size 256 next 9\n",
      "2025-07-30 19:19:17.004721: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9021d900 of size 61696 next 23\n",
      "2025-07-30 19:19:17.004724: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022ca00 of size 512 next 18\n",
      "2025-07-30 19:19:17.004727: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022cc00 of size 768 next 21\n",
      "2025-07-30 19:19:17.004730: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022cf00 of size 256 next 32\n",
      "2025-07-30 19:19:17.004733: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022d000 of size 256 next 33\n",
      "2025-07-30 19:19:17.004737: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022d100 of size 256 next 34\n",
      "2025-07-30 19:19:17.004740: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022d200 of size 256 next 35\n",
      "2025-07-30 19:19:17.004743: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022d300 of size 256 next 36\n",
      "2025-07-30 19:19:17.004746: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022d400 of size 1280 next 37\n",
      "2025-07-30 19:19:17.004749: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022d900 of size 256 next 38\n",
      "2025-07-30 19:19:17.004752: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9022da00 of size 61440 next 24\n",
      "2025-07-30 19:19:17.004755: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9023ca00 of size 512 next 19\n",
      "2025-07-30 19:19:17.004759: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9023cc00 of size 65536 next 14\n",
      "2025-07-30 19:19:17.004762: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9024cc00 of size 130560 next 30\n",
      "2025-07-30 19:19:17.004765: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9026ca00 of size 256 next 39\n",
      "2025-07-30 19:19:17.004768: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9026cb00 of size 512 next 41\n",
      "2025-07-30 19:19:17.004771: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9026cd00 of size 512 next 42\n",
      "2025-07-30 19:19:17.004775: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d9026cf00 of size 97024 next 29\n",
      "2025-07-30 19:19:17.004778: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 148d90284a00 of size 63878656 next 18446744073709551615\n",
      "2025-07-30 19:19:17.004781: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2025-07-30 19:19:17.004786: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 27 Chunks of size 256 totalling 6.8KiB\n",
      "2025-07-30 19:19:17.004959: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 8 Chunks of size 512 totalling 4.0KiB\n",
      "2025-07-30 19:19:17.004964: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 768 totalling 1.5KiB\n",
      "2025-07-30 19:19:17.004967: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 1280 totalling 5.0KiB\n",
      "2025-07-30 19:19:17.004971: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 36864 totalling 36.0KiB\n",
      "2025-07-30 19:19:17.004975: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 61440 totalling 60.0KiB\n",
      "2025-07-30 19:19:17.004979: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 61696 totalling 60.2KiB\n",
      "2025-07-30 19:19:17.004983: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 65536 totalling 64.0KiB\n",
      "2025-07-30 19:19:17.004987: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 97024 totalling 94.8KiB\n",
      "2025-07-30 19:19:17.004991: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 98304 totalling 96.0KiB\n",
      "2025-07-30 19:19:17.004995: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 130560 totalling 127.5KiB\n",
      "2025-07-30 19:19:17.004999: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 56623104 totalling 54.00MiB\n",
      "2025-07-30 19:19:17.005003: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 63878656 totalling 60.92MiB\n",
      "2025-07-30 19:19:17.005006: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 113220352 totalling 107.97MiB\n",
      "2025-07-30 19:19:17.005010: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 223.44MiB\n",
      "2025-07-30 19:19:17.005014: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 234291200 memory_limit_: 234291200 available bytes: 0 curr_region_allocation_bytes_: 468582400\n",
      "2025-07-30 19:19:17.005021: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                       234291200\n",
      "InUse:                       234291200\n",
      "MaxInUse:                    234291200\n",
      "NumAllocs:                          88\n",
      "MaxAllocSize:                113220352\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-07-30 19:19:17.005028: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *************************************************xxxxxxxxxxxxxxxxxxxxxxx*************************xxx\n",
      "2025-07-30 19:19:17.009242: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at constant_op.cc:175 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_model_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ens1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Loading and predicting with model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m pred_4xco2_norm \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(TS_4xCO2_norm)\n\u001b[1;32m     83\u001b[0m pred_4xco2_unnorm \u001b[38;5;241m=\u001b[39m pred_4xco2_norm \u001b[38;5;241m*\u001b[39m y_std \u001b[38;5;241m+\u001b[39m y_mean\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:171\u001b[0m, in \u001b[0;36mZeros.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mcall_with_layout(\n\u001b[1;32m    169\u001b[0m         tf\u001b[38;5;241m.\u001b[39mzeros, layout, shape\u001b[38;5;241m=\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# FINAL OUT-OF-SAMPLE TEST SCRIPT FOR 2D ZONAL-MEAN MODELS\n",
    "# ==========================================================\n",
    "# This script contains all necessary code and corrected paths.\n",
    "# Please use this to replace your entire out-of-sample notebook.\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from keras.models import load_model\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# --- 1. Configuration: Set ONE Correct Path for Model Results ---\n",
    "print(\"--- Setting up for Zonal-Mean Out-of-Sample Test ---\")\n",
    "\n",
    "# For CESM1:\n",
    "#path_model_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model_2D_changedLRandKS'\n",
    "# For CESM2:\n",
    "path_model_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM2/trained_model_2D_changedLRandKS'\n",
    "\n",
    "# Define variable names for your test files\n",
    "In_name = \"TS\"\n",
    "Out_name = \"TOA_anom\"\n",
    "\n",
    "# Define paths to your TWO separate 4xCO2 test files\n",
    "# # For CESM1:\n",
    "# file_4xCO2_input = \"/ocean/projects/ees250004p/ezhu3/data/CESM1/test/test.4xCO2.ANN.new.nc\"\n",
    "# file_4xCO2_output = \"/ocean/projects/ees250004p/ezhu3/data/CESM1/test/test.4xCO2.zmean.ANN.new.nc\"\n",
    "\n",
    "# For CESM2:\n",
    "file_4xCO2_input = \"/ocean/projects/ees250004p/ezhu3/data/CESM2/test/test.CESM2-4xCO2.ANN.nc\"\n",
    "file_4xCO2_output = \"/ocean/projects/ees250004p/ezhu3/data/CESM2/test/test.CESM2-4xCO2.zmean.ANN.nc\"\n",
    "\n",
    "# --- 2. Load Normalization Data from the Training Run ---\n",
    "print(\"Loading normalization data...\")\n",
    "normalization_path = os.path.join(path_model_dir, 'Normalization_zonal.mat')\n",
    "normalization = sio.loadmat(normalization_path)\n",
    "X_mean = normalization['X_mean']\n",
    "X_std = normalization['X_std']\n",
    "y_mean = normalization['y_mean']\n",
    "y_std = normalization['y_std']\n",
    "print(\"✅ Normalization data loaded successfully.\")\n",
    "print(X_mean)\n",
    "print(X_std)\n",
    "print(y_mean)\n",
    "print(y_std)\n",
    "# --- 3. Load and Preprocess 4xCO2 Test Data ---\n",
    "print(\"\\nLoading and preprocessing 4xCO2 test data...\")\n",
    "ds_4xCO2_X = xr.open_dataset(file_4xCO2_input)\n",
    "ds_4xCO2_y = xr.open_dataset(file_4xCO2_output)\n",
    "\n",
    "# Extract variables from the correct files\n",
    "TS_4xCO2_raw = ds_4xCO2_X[In_name]\n",
    "TOA_4xCO2_truth = ds_4xCO2_y[Out_name].values\n",
    "lat = ds_4xCO2_X['lat'].values\n",
    "time_4xCO2 = ds_4xCO2_X['year'].values if 'year' in ds_4xCO2_X else ds_4xCO2_X['time'].values\n",
    "\n",
    "# Normalize inputs correctly by adding the channel dimension first\n",
    "TS_4xCO2_norm = (TS_4xCO2_raw.values[..., np.newaxis] - X_mean) / X_std\n",
    "print(\"✅ Test data preprocessed.\")\n",
    "\n",
    "# --- 4. Prediction Loop ---\n",
    "print(\"\\n--- Running Ensemble Predictions for 4xCO2 ---\")\n",
    "n_folds = 5\n",
    "predictions_from_folds = []\n",
    "\n",
    "for fold_no in range(1, n_folds + 1):\n",
    "    K.clear_session(); gc.collect()\n",
    "    \n",
    "    # Use the corrected, direct path to load the model\n",
    "    model_path = os.path.join(path_model_dir, f'model_fold{fold_no}_ens1.h5')\n",
    "    print(f\"    Loading and predicting with model: {model_path}\")\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    pred_4xco2_norm = model.predict(TS_4xCO2_norm)\n",
    "    pred_4xco2_unnorm = pred_4xco2_norm * y_std + y_mean\n",
    "    predictions_from_folds.append(pred_4xco2_unnorm)\n",
    "\n",
    "# Average predictions across the folds\n",
    "Model_pred_4xco2 = np.mean(np.stack(predictions_from_folds), axis=0)\n",
    "print(\"\\n✅ Prediction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60dd36-d92c-4163-b95f-971daad94051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Out-of-Sample Analysis and Visualization (Corrected Plotting Axis)\n",
    "# ==========================================================\n",
    "print(\"\\n--- Starting Out-of-Sample Analysis ---\")\n",
    "\n",
    "# --- Task 1: Calculate Overall Pattern Correlation ---\n",
    "print(\"\\n    Calculating Overall Pattern Correlation...\")\n",
    "truth_flat = TOA_4xCO2_truth.flatten()\n",
    "pred_flat = Model_pred_4xco2.flatten()\n",
    "pattern_r, _ = pearsonr(truth_flat, pred_flat)\n",
    "print(f\"✅ Overall Pattern Correlation (r) = {pattern_r:.4f}\")\n",
    "\n",
    "# --- Task 2: Plot R-squared as a Function of Latitude ---\n",
    "print(\"\\n    Calculating and plotting R-squared per latitude...\")\n",
    "r2_by_latitude = [r2_score(TOA_4xCO2_truth[:, i], Model_pred_4xco2[:, i]) for i in range(len(lat))]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lat, r2_by_latitude, marker='o', linestyle='-')\n",
    "plt.title('Out-of-Sample Performance (R²) by Latitude - 4xCO2', fontsize=16)\n",
    "plt.xlabel('Latitude', fontsize=12)\n",
    "plt.ylabel('R-squared Score', fontsize=12)\n",
    "plt.grid(True, linestyle='--'); plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# --- Task 3: Plot Truth vs. Prediction as a 2D Contour Map ---\n",
    "print(\"\\n    Plotting Truth vs. Prediction as contour maps...\")\n",
    "\n",
    "# This creates a simple numerical axis [0, 1, 2, ...] for plotting\n",
    "time_axis_for_plot = np.arange(TOA_4xCO2_truth.shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6), sharey=True)\n",
    "vmax = np.percentile(np.abs(TOA_4xCO2_truth), 98)\n",
    "vmin = -vmax\n",
    "\n",
    "axes[0].set_title('Ground Truth TOA Zonal Mean', fontsize=16)\n",
    "# Use the new simple time axis for plotting\n",
    "cf1 = axes[0].contourf(time_axis_for_plot, lat, TOA_4xCO2_truth.T, levels=20, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "axes[0].set_xlabel('Time (Model Years)', fontsize=12)\n",
    "axes[0].set_ylabel('Latitude', fontsize=12)\n",
    "\n",
    "axes[1].set_title('Predicted TOA Zonal Mean', fontsize=16)\n",
    "# Use the new simple time axis for plotting here as well\n",
    "cf2 = axes[1].contourf(time_axis_for_plot, lat, Model_pred_4xco2.T, levels=20, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "axes[1].set_xlabel('Time (Model Years)', fontsize=12)\n",
    "\n",
    "fig.colorbar(cf1, ax=axes.ravel().tolist(), shrink=0.8, label='TOA Anomaly (W/m²)')\n",
    "fig.suptitle(\"Out-of-Sample Results - 4xCO2 Scenario\", fontsize=18, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470f59c-3312-4733-9169-81bb557753ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Task 4: Calculate and Compare Global Mean Time Series\n",
    "# =========================================================\n",
    "print(\"\\n--- Calculating and Comparing Weighted Global Means ---\")\n",
    "\n",
    "# --- Step 1: Calculate Latitude Weights ---\n",
    "# To get a true global mean, we must weight each latitude by the cosine\n",
    "# of its angle to account for the smaller grid cell areas near the poles.\n",
    "lat_radians = np.deg2rad(lat)\n",
    "weights = np.cos(lat_radians)\n",
    "# Ensure weights have the correct shape for broadcasting during the average\n",
    "weights = weights[np.newaxis, :]\n",
    "\n",
    "# --- Step 2: Calculate Weighted Average for Truth and Prediction ---\n",
    "# We average over the latitude axis (axis=1) to get a single global\n",
    "# mean value for each time step.\n",
    "global_mean_truth = np.average(TOA_4xCO2_truth, axis=1, weights=weights.flatten())\n",
    "global_mean_pred = np.average(Model_pred_4xco2, axis=1, weights=weights.flatten())\n",
    "\n",
    "print(\"✅ Weighted global means calculated.\")\n",
    "\n",
    "# --- Step 3: Print and Compare the Overall Mean Values ---\n",
    "# This gives a single number summary of the entire time series\n",
    "print(f\"    Overall Mean of Ground Truth: {np.mean(global_mean_truth):.4f} W/m²\")\n",
    "print(f\"    Overall Mean of Prediction:   {np.mean(global_mean_pred):.4f} W/m²\")\n",
    "\n",
    "# --- Step 4: Plot the Global Mean Time Series for Comparison ---\n",
    "print(\"\\n    Plotting global mean time series comparison...\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "time_axis_for_plot = np.arange(global_mean_truth.shape[0])\n",
    "\n",
    "plt.plot(time_axis_for_plot, global_mean_truth, label='Ground Truth', color='black', linewidth=2)\n",
    "plt.plot(time_axis_for_plot, global_mean_pred, label='Model Prediction', color='red', linestyle='--')\n",
    "\n",
    "plt.title('Out-of-Sample: Global Mean TOA Anomaly Time Series', fontsize=16)\n",
    "plt.xlabel('Time (Model Years)', fontsize=12)\n",
    "plt.ylabel('Global Mean Anomaly (W/m²)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025f18b-9ebb-4058-ae42-5357b6e20c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Task 4: Calculate and Compare Global Mean Time Series\n",
    "# =========================================================\n",
    "print(\"\\n--- Calculating and Comparing Weighted Global Means ---\")\n",
    "\n",
    "# --- Step 1: Calculate Latitude Weights ---\n",
    "# To get a true global mean, we must weight each latitude by the cosine\n",
    "# of its angle to account for the smaller grid cell areas near the poles.\n",
    "lat_radians = np.deg2rad(lat)\n",
    "weights = np.cos(lat_radians)\n",
    "# Ensure weights have the correct shape for broadcasting during the average\n",
    "weights = weights[np.newaxis, :]\n",
    "\n",
    "# --- Step 2: Calculate Weighted Average for Truth and Prediction ---\n",
    "# We average over the latitude axis (axis=1) to get a single global\n",
    "# mean value for each time step.\n",
    "global_mean_truth = np.average(TOA_4xCO2_truth, axis=1, weights=weights.flatten())\n",
    "global_mean_pred = np.average(Model_pred_4xco2, axis=1, weights=weights.flatten())\n",
    "\n",
    "print(\"✅ Weighted global means calculated.\")\n",
    "\n",
    "# --- Step 3: Print and Compare the Overall Mean Values ---\n",
    "# This gives a single number summary of the entire time series\n",
    "print(f\"    Overall Mean of Ground Truth: {np.mean(global_mean_truth):.4f} W/m²\")\n",
    "print(f\"    Overall Mean of Prediction:   {np.mean(global_mean_pred):.4f} W/m²\")\n",
    "\n",
    "# --- Step 4: Plot the Global Mean Time Series for Comparison ---\n",
    "print(\"\\n    Plotting global mean time series comparison...\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "time_axis_for_plot = np.arange(global_mean_truth.shape[0])\n",
    "\n",
    "plt.plot(time_axis_for_plot, global_mean_truth, label='Ground Truth', color='black', linewidth=2)\n",
    "plt.plot(time_axis_for_plot, global_mean_pred, label='Model Prediction', color='red', linestyle='--')\n",
    "\n",
    "plt.title('Out-of-Sample: Global Mean TOA Anomaly Time Series', fontsize=16)\n",
    "plt.xlabel('Time (Model Years)', fontsize=12)\n",
    "plt.ylabel('Global Mean Anomaly (W/m²)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbe86a-9ace-4a66-893d-6231e0ecefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# Task 5: Calculate and Plot Climate Feedback Parameter (λ)\n",
    "# =================================================================\n",
    "from scipy.stats import linregress\n",
    "\n",
    "print(\"\\n--- Calculating and Plotting Climate Feedback Parameter (λ) ---\")\n",
    "\n",
    "# --- Step 1: Calculate the X-axis data (Area-Weighted Global Mean TS Anomaly) ---\n",
    "# We already have the latitude weights from the previous task.\n",
    "# First, take the mean across the longitude axis of the raw input data.\n",
    "TS_zonal_mean_truth = np.mean(TS_4xCO2_raw.values, axis=2)\n",
    "\n",
    "# Now, calculate the latitude-weighted average to get the global mean.\n",
    "global_mean_TS_truth = np.average(TS_zonal_mean_truth, axis=1, weights=weights.flatten())\n",
    "\n",
    "# --- Step 2: Set up the side-by-side plots ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "fig.suptitle('Climate Feedback Parameter (λ) - 4xCO2 Out-of-Sample', fontsize=20, weight='bold')\n",
    "\n",
    "# --- Step 3: Plot for the Ground Truth ---\n",
    "ax1 = axes[0]\n",
    "# Perform linear regression to find the slope (lambda)\n",
    "slope_truth, intercept_truth, r_value_truth, _, _ = linregress(global_mean_TS_truth, global_mean_truth)\n",
    "lambda_truth = slope_truth\n",
    "r2_truth = r_value_truth**2\n",
    "\n",
    "# Scatter plot\n",
    "ax1.scatter(global_mean_TS_truth, global_mean_truth, alpha=0.6, label='Yearly Data (Ground Truth)')\n",
    "# Best-fit line\n",
    "fit_line_truth = slope_truth * global_mean_TS_truth + intercept_truth\n",
    "ax1.plot(global_mean_TS_truth, fit_line_truth, color='red', linestyle='--', label='Linear Best Fit')\n",
    "\n",
    "# Add text box with results\n",
    "text_truth = (f'λ = {lambda_truth:.3f} W/m²/K\\n'\n",
    "              f'$R^2$ = {r2_truth:.3f}')\n",
    "ax1.text(0.05, 0.95, text_truth, transform=ax1.transAxes, fontsize=14,\n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "ax1.set_title('Ground Truth Data', fontsize=16)\n",
    "ax1.set_xlabel('Area-Weighted Global Mean TS Anomaly (K)', fontsize=12)\n",
    "ax1.set_ylabel('Global Mean TOA Anomaly (W/m²)', fontsize=12)\n",
    "ax1.grid(True, linestyle=':')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "# --- Step 4: Plot for the Model Prediction ---\n",
    "ax2 = axes[1]\n",
    "# Perform linear regression\n",
    "slope_pred, intercept_pred, r_value_pred, _, _ = linregress(global_mean_TS_truth, global_mean_pred)\n",
    "lambda_pred = slope_pred\n",
    "r2_pred = r_value_pred**2\n",
    "\n",
    "# Scatter plot\n",
    "ax2.scatter(global_mean_TS_truth, global_mean_pred, alpha=0.6, label='Yearly Data (Model Prediction)')\n",
    "# Best-fit line\n",
    "fit_line_pred = slope_pred * global_mean_TS_truth + intercept_pred\n",
    "ax2.plot(global_mean_TS_truth, fit_line_pred, color='red', linestyle='--', label='Linear Best Fit')\n",
    "\n",
    "# Add text box with results\n",
    "text_pred = (f'λ = {lambda_pred:.3f} W/m²/K\\n'\n",
    "             f'$R^2$ = {r2_pred:.3f}')\n",
    "ax2.text(0.05, 0.95, text_pred, transform=ax2.transAxes, fontsize=14,\n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "ax2.set_title('Model Prediction', fontsize=16)\n",
    "ax2.set_xlabel('Area-Weighted Global Mean TS Anomaly (K)', fontsize=12)\n",
    "# No Y-label needed as it's shared with ax1\n",
    "ax2.grid(True, linestyle=':')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make room for suptitle\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf210)",
   "language": "python",
   "name": "tf210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
