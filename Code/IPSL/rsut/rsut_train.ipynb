{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b88c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 12:59:41.245004: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-29 12:59:42.484591: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-29 12:59:42.749383: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,LeakyReLU, Dropout, Add, Activation, Conv2D, Flatten, MaxPooling2D, Dense, PReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from matplotlib.colors import Normalize\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "tf.config.list_physical_devices('GPU')  \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras.engine.training_v1\")\n",
    "import xarray as xr\n",
    "import innvestigate\n",
    "import scipy.io as sio\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c3435-9030-45fd-9f63-4821b48f1294",
   "metadata": {},
   "source": [
    "##IMPORTANT!!\n",
    "NEED TO CHANGE INPUT/OUTPUT path for CESM1/CESM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560eda33",
   "metadata": {
    "title": "load data"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/coding/times.py:716: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/core/indexing.py:529: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(array[self.key], dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (time: 800, bnds: 2, lon: 144, lat: 143)\n",
      "Coordinates:\n",
      "  * time       (time) object 3050-07-01 06:00:00 ... 3849-07-01 06:00:00\n",
      "  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
      "  * lat        (lat) float32 -90.0 -88.73 -87.46 -86.2 ... 86.2 87.46 88.73 90.0\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    time_bnds  (time, bnds) object ...\n",
      "    ts         (time, lat, lon) float32 ...\n",
      "Attributes: (12/53)\n",
      "    CDI:                    Climate Data Interface version 2.5.0 (https://mpi...\n",
      "    Conventions:            CF-1.7 CMIP-6.2\n",
      "    source:                 IPSL-CM6A-LR (2017):  atmos: LMDZ (NPv6, N96; 144...\n",
      "    institution:            Institut Pierre Simon Laplace, Paris 75252, France\n",
      "    name:                   /ccc/work/cont003/gencmip6/p86mign/IGCM_OUT/IPSLC...\n",
      "    creation_date:          2019-06-28T11:56:10Z\n",
      "    ...                     ...\n",
      "    dr2xml_md5sum:          45d4369d889ddfb8149d771d8625e9ec\n",
      "    model_version:          6.1.9\n",
      "    parent_experiment_id:   piControl-spinup\n",
      "    parent_activity_id:     CMIP\n",
      "    NCO:                    netCDF Operators version 5.3.4 (Homepage = http:/...\n",
      "    CDO:                    Climate Data Operators version 2.5.0 (https://mpi...\n",
      "Aligning data to the shortest length: 800 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/coding/times.py:716: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/coding/times.py:716: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/core/indexing.py:529: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(array[self.key], dtype=None)\n",
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/coding/times.py:716: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/coding/times.py:716: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/coding/times.py:716: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/jet/home/ezhu3/.conda/envs/tf210/lib/python3.8/site-packages/xarray/core/indexing.py:529: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(array[self.key], dtype=None)\n"
     ]
    }
   ],
   "source": [
    "# load the input variable -- global Surface temperature\n",
    "\n",
    "#CESM1 control\n",
    "#ds = xr.open_dataset(\"/ocean/projects/ees250004p/ezhu3/data/CESM1/control/input.B1850C5CN.TS.ANN.0400-2200.new.nc\")\n",
    "\n",
    "#CESM2 data 1: \n",
    "#ds = xr.open_dataset(\"/ocean/projects/ees250004p/ezhu3/data/CESM2/control/input.CESM2-B1850.TS_detrend.ANN.nc\")\n",
    "\n",
    "#CESM2 data2:\n",
    "#ds = xr.open_dataset(\"/ocean/projects/ees250004p/ezhu3/data/CESM2/control/input.CESM2-B1850.TS.ANN.nc\")\n",
    "\n",
    "#ds = xr.open_dataset(\"E:\\\\Yue\\\\CESM2\\\\control\\\\input.CESM2-B1850.TS_detrend.ANN.nc\")# Display dataset info\n",
    "ds = xr.open_dataset(\"/ocean/projects/ees250004p/ezhu3/data/IPSL-CM6A_LR/control/ts/proc/IPSL_piControl_ts_anom.nc\")\n",
    "print(ds)\n",
    "\n",
    "# Access a specific variable\n",
    "TS = ds[\"ts\"] # Surface temperature (radiative)     units = 'K'\n",
    "lat = ds[\"lat\"] #latitude\n",
    "lon = ds[\"lon\"] #longitude\n",
    "time = ds[\"time\"]\n",
    "\n",
    "\n",
    "# Define the directory where the output variables are stored\n",
    "data_dir = '/ocean/projects/ees250004p/ezhu3/data/IPSL-CM6A_LR/control/rsut/proc/' #this is for CESM1\n",
    "# Define the filenames and corresponding variable names\n",
    "files = {\n",
    "    #CESM1:\n",
    "    #\"TOA_anom\": \"output.B1850C5CN.TOA.gmean.ANN.0400-2200.new.nc\"\n",
    "    \n",
    "    #CESM2 data 1:\n",
    "    #\"TOA_anom\": \"output.CESM2-B1850.TOA_detrend.ANN.nc\"\n",
    "    #CESM2 data 2:\n",
    "    #\"TOA_anom\": \"output.CESM2-B1850.TOA.ANN.nc\"\n",
    "    \"rsut\":\"IPSL_piControl_rsut_annual_anom.nc\"\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "# Load variables\n",
    "for var, filename in files.items():\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    datasets[var] = ds[var]  # Extract only the variable\n",
    "\n",
    "\n",
    "# Now the variables can be accessed as datasets[\"CRE\"], datasets[\"TOA\"], etc.\n",
    "\n",
    "\n",
    "# path for storing the trained neural networks\n",
    "#data_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM2/trained_model_data1_Gelu'#CESM2 data1\n",
    "#data_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM2/trained_model_data2_Gelu'#CESM2 data2 gelu\n",
    "#data_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model'#CESM1\n",
    "data_dir = '/ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model_rsut'#CESM1 Gelu\n",
    "\n",
    "\n",
    "# Load X data (ts)\n",
    "ds_X = xr.open_dataset(\"/ocean/projects/ees250004p/ezhu3/data/IPSL-CM6A_LR/control/ts/proc/IPSL_piControl_ts_anom.nc\")\n",
    "ts_data = ds_X[\"ts\"]\n",
    "\n",
    "# Load Y data (rsdt)\n",
    "data_dir_y = '/ocean/projects/ees250004p/ezhu3/data/IPSL-CM6A_LR/control/rsut/proc/'\n",
    "rsdt_filename = \"IPSL_piControl_rsut_annual_anom.nc\" \n",
    "ds_Y = xr.open_dataset(os.path.join(data_dir_y, rsdt_filename))\n",
    "rsdt_data = ds_Y[\"rsut\"]\n",
    "\n",
    "# --- Step 2: Find the minimum length and slice both arrays ---\n",
    "# Find the shortest time dimension\n",
    "min_length = min(len(ts_data['time']), len(rsdt_data['time']))\n",
    "print(f\"Aligning data to the shortest length: {min_length} samples.\")\n",
    "\n",
    "# Use .isel() to select the first 'min_length' time steps from both\n",
    "ts_aligned = ts_data.isel(time=slice(0, min_length))\n",
    "rsdt_aligned = rsdt_data.isel(time=slice(0, min_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3dd24db",
   "metadata": {
    "title": "Neural Network Hyperparameters"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "            \n",
    "# Neural network architecture:\n",
    "# Example: [64, 64, 64] means three hidden layers, each containing 64 neurons.\n",
    "kernels = [32, 32]\n",
    "kernel_acts =  [\"gelu\", \"gelu\"]\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "rng_seed = 42\n",
    "hiddens = [16, 8]\n",
    "activation_function_dense = [\"PRelu\", \"PRelu\"]\n",
    "pool_size = 2\n",
    "\n",
    "# Loss function for regression tasks:\n",
    "# Options: 'mse' (mean squared error), 'mae' (mean absolute error), 'mape' (mean absolute percentage error)\n",
    "# Full list of regression losses: https://keras.io/api/losses/\n",
    "loss_function = 'mse'\n",
    "\n",
    "\n",
    "reg_strength = 0         # L2 regularization strength; 1e-1~1e-5\n",
    "dropout_rate = 0.25         # Dropout rate (0.0 to disable dropout)\n",
    "\n",
    "\n",
    "# low-pass filter time scale; 0 means no low-pass filter\n",
    "LPF_year = 0\n",
    "\n",
    "\n",
    "#### normalization\n",
    "remove_mean = 0\n",
    "divide_std = 1\n",
    "\n",
    "\n",
    "#### usually we do not change the parameters below \n",
    "\n",
    "# Training configuration\n",
    "epoch_max = 25000            # Maximum number of training epochs\n",
    "batch_size = 32            # Batch size used during training\n",
    "learning_rate = 0.000005       # Default learning rate for Adam optimizer 0.001\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "num_folds = 5 # Number of fold during cross-validation\n",
    "NNrepeats = 1 # Repeat the training for NNrepeats times\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c050e93",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "pre-process data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of X: (800, 143, 144)\n",
      "Final shape of y: (800, 1)\n",
      "Corrected input shape: (800, 143, 144)\n",
      "Corrected output shape: (800, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_raw = ts_aligned.values\n",
    "\n",
    "# Prepare y (output_raw) by taking the spatial mean of the ALIGNED data\n",
    "output_raw = rsdt_aligned.mean(dim=['lat', 'lon']).values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# --- Step 4: Verification ---\n",
    "print(\"Final shape of X:\", input_raw.shape)\n",
    "print(\"Final shape of y:\", output_raw.shape)\n",
    "\n",
    "# input_raw = TS.values.reshape(TS.shape[0],TS.shape[1]*TS.shape[2])\n",
    "# For CNN, we don't need to flatten the data\n",
    "# input_raw = TS.values\n",
    "\n",
    "\n",
    "\n",
    "# Define the variable names as a comma-separated string\n",
    "# names_strALL = \"CRE,FLNT,FSNT,LCC,LWCF,SWCF,TCC,TOA\"\n",
    "# If we only want to reconstruct TOA\n",
    "names_strALL = \"rsdt\"\n",
    "names_str = \"rsdt\"\n",
    "\n",
    "#mean_values = datasets[names_str].mean(dim=['lat', 'lon']).values\n",
    "# --- Verification ---\n",
    "print(\"Corrected input shape:\", input_raw.shape)\n",
    "print(\"Corrected output shape:\", output_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49bea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_NN_name():\n",
    "\n",
    "    NN_name = 'CNN'\n",
    "        \n",
    "    activation_function_str = '_'+kernel_acts[0]+ '+'+activation_function_dense[0] \n",
    "    loss_function_str = '_'+str(loss_function)+'loss' if loss_function!='mse' else ''\n",
    "    \n",
    "    if remove_mean + divide_std == 0:\n",
    "        scaler_str = 'NoScaler_'\n",
    "    elif remove_mean + divide_std == 2:\n",
    "        scaler_str = 'StandardScaler_'\n",
    "    elif remove_mean:\n",
    "        scaler_str = 'RemoveMean_'\n",
    "    elif divide_std:\n",
    "        scaler_str = 'DivideSTD_'\n",
    "    LPF_str = f'_LPF{int(LPF_year)}Year' if LPF_year else ''\n",
    "    NN_structure_str = 'x'.join(map(str, kernels)) \n",
    "    reg_str = f'Reg{reg_strength}' + (f'Drop{dropout_rate}' if dropout_rate != 0 else '')\n",
    "    batch_size_str =  f'BS{batch_size}_' if batch_size !=600 else ''\n",
    "    return f\"{NN_name}_{scaler_str}Neur{NN_structure_str}_{batch_size_str}{num_folds}foldCV_{reg_str}{loss_function_str}{activation_function_str}{LPF_str}\"\n",
    "NN_name = create_NN_name()\n",
    "\n",
    "    \n",
    "def construct_output_directory(data_dir, NN_name):\n",
    "    output_dir = os.path.join(data_dir, 'NeuralNet', NN_name, names_str)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "output_dir = construct_output_directory(data_dir, NN_name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840c1afa",
   "metadata": {
    "title": "Define logger that can print useful information into a logfile"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 12:59:51,515 - logfile\n",
      "2025-08-29 12:59:51.532607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-29 12:59:52.529816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 169 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "2025-08-29 12:59:52,536 - Using GPU for training.\n",
      "2025-08-29 12:59:52,536 - 1 Physical GPUs, 1 Logical GPUs\n",
      "2025-08-29 12:59:52,537 - None\n",
      "2025-08-29 12:59:52,538 - Output path: created successfully\n",
      "2025-08-29 12:59:52,538 - The output path is /ocean/projects/ees250004p/ezhu3/data/CESM1/trained_model_rsut/NeuralNet/CNN_DivideSTD_Neur32x32_BS32_5foldCV_Reg0Drop0.25_gelu+PRelu/rsdt\n"
     ]
    }
   ],
   "source": [
    "logger_name = 'logfile.log'  \n",
    "# Configure logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create handlers\n",
    "file_handler = logging.FileHandler(os.path.join(output_dir, logger_name))\n",
    "console_handler = logging.StreamHandler()\n",
    "\n",
    "# Set level and format for handlers\n",
    "file_handler.setLevel(logging.INFO)\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Test the setup\n",
    "logger.info(\"logfile\")\n",
    "\n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    logger.info(\"Using GPU for training.\")\n",
    "    logger.info(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "else:\n",
    "    logger.info(\"Using CPU for training.\") \n",
    "\n",
    "logger.info(os.getenv('TF_GPU_ALLOCATOR'))\n",
    "    \n",
    "logger.info(f\"Output path: {'created successfully' if os.path.exists(output_dir) else 'already exists'}\")\n",
    "logger.info(f\"The output path is {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d9886a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 12:59:52,545 - ------------------------------------------------------------------------\n",
      "2025-08-29 12:59:52,546 - ------------------------------------------------------------------------\n",
      "2025-08-29 12:59:52,546 - Applying 0-year low pass filter ...\n",
      "2025-08-29 12:59:52,547 - ------------------------------------------------------------------------\n",
      "2025-08-29 12:59:52,547 - ------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.info('------------------------------------------------------------------------')\n",
    "logger.info('------------------------------------------------------------------------')\n",
    "logger.info(f'Applying {LPF_year}-year low pass filter ...')\n",
    "logger.info('------------------------------------------------------------------------')\n",
    "logger.info('------------------------------------------------------------------------')\n",
    "\n",
    "from scipy.signal import butter, sosfilt\n",
    "\n",
    "def apply_low_pass_filter(data, cutoff_freq, order=5, sampling_rate=1, padding_length=None):\n",
    "    \"\"\"Applies a Butterworth low-pass filter to the given data.\"\"\"\n",
    "    sos = butter(order, cutoff_freq, btype='low', output='sos', analog=False, fs=sampling_rate)\n",
    "    \n",
    "    # Apply Boundary Padding to the data before filtering\n",
    "    padded_data = np.pad(data, [(padding_length, padding_length), (0, 0)], mode='reflect')\n",
    "    \n",
    "    # Apply the filter across each column without explicit looping\n",
    "    filtered_data = sosfilt(sos, padded_data, axis=0)\n",
    "    \n",
    "    # Remove padding\n",
    "    return filtered_data[padding_length:-padding_length]\n",
    "\n",
    "if LPF_year:\n",
    "    # Calculate the sampling rate (monthly data)\n",
    "    sampling_rate = 1  # Data is sampled monthly    \n",
    "    cutoff_freq = 1 / LPF_year\n",
    "    order = 5\n",
    "    padding_length =  3* LPF_year\n",
    "\n",
    "if LPF_year:\n",
    "    input = apply_low_pass_filter(input_raw, cutoff_freq, order, sampling_rate, padding_length)     \n",
    "    output= apply_low_pass_filter(output_raw, cutoff_freq, order, sampling_rate, padding_length)     \n",
    "    \n",
    "    plt.figure(figsize=(30, 6))  \n",
    "    plt.plot(time, output_raw, label=\"Original\", color=\"C0\", linewidth=2)  # Use color and linewidth\n",
    "    plt.plot(time, output, label=\"Low-pass filtered\", color=\"C1\", linestyle=\"-\", linewidth=1.5)  # Dashed line for prediction\n",
    "    plt.xlabel(\"Time (year)\", fontsize=14)\n",
    "    plt.ylabel(names_str, fontsize=14)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(fontsize=12, loc=\"best\")\n",
    "    plt.savefig(os.path.join(output_dir, names_str+\"_LPF.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "else:\n",
    "    input  =  input_raw\n",
    "    output = output_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#                       define the neural network                     #\n",
    "#######################################################################\n",
    "\n",
    "log_path =os.path.join(output_dir, 'training_logs.txt')\n",
    "os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "class PrintTrainingOnTextEvery10EpochsCallback(Callback):\n",
    "    def __init__(self, log_path):\n",
    "        super().__init__()\n",
    "        self.log_path = log_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:  # Log every 10 epochs\n",
    "            with open(self.log_path, \"a\") as log_file:\n",
    "                log_file.write(\n",
    "                    f\"Epoch: {epoch:>3} | \"\n",
    "                    f\"Loss: {logs.get('loss', 0):.2e} | \"\n",
    "#                        f\"Accuracy: {logs.get('accuracy', 0):.2e} | \"\n",
    "                    f\"Validation loss: {logs.get('val_loss', 0):.2e} |\\n \"\n",
    "#                        f\"Validation accuracy: {logs.get('val_accuracy', 0):.2e}\\n\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"Epoch {epoch:>3} - \"\n",
    "                    f\"Loss: {logs.get('loss', 0):.2e}, \"\n",
    "#                        f\"Accuracy: {logs.get('accuracy', 0):.2e}, \"\n",
    "                    f\"Validation loss: {logs.get('val_loss', 0):.2e}, \"\n",
    "#                        f\"Validation accuracy: {logs.get('val_accuracy', 0):.2e}\"\n",
    "                )\n",
    "\n",
    "my_callbacks = [\n",
    "    PrintTrainingOnTextEvery10EpochsCallback(log_path=log_path),\n",
    "]   \n",
    "\n",
    "        \n",
    "def train_model(X_train, y_train, X_test, y_test, y_mean, y_std):\n",
    "    inputs = tf.keras.Input(shape=(X_train.shape[1:]),)\n",
    "    layers = inputs\n",
    "\n",
    "    # Convolutional Layers\n",
    "    for i, kernel_filters in enumerate(kernels):  \n",
    "        layers = Conv2D(\n",
    "            kernel_filters,\n",
    "            (kernel_size, kernel_size),  \n",
    "            strides=(stride, stride),      \n",
    "            use_bias=True,\n",
    "            padding=\"same\",\n",
    "            # NO 'activation' argument here if PReLU or another layer follows\n",
    "            bias_initializer=tf.keras.initializers.RandomNormal(seed=rng_seed),\n",
    "            kernel_initializer=tf.keras.initializers.RandomNormal(seed=rng_seed),\n",
    "        )(layers)\n",
    "\n",
    "        # Apply PReLU (or other chosen activation)\n",
    "        if kernel_acts[i].lower() == 'prelu':\n",
    "            layers = PReLU(shared_axes=[1, 2],\n",
    "                           alpha_initializer=tf.keras.initializers.Constant(0.25) # Common starting point\n",
    "                          )(layers) # shared_axes for Conv2D with channels_last\n",
    "        elif kernel_acts[i].lower() == 'gelu':\n",
    "            layers = tf.keras.layers.Activation('gelu')(layers) # Using Activation layer for GeLU\n",
    "        elif kernel_acts[i]: # For 'relu', 'elu', etc.\n",
    "            layers = tf.keras.layers.Activation(kernel_acts[i])(layers)\n",
    "        # If kernel_acts[i] is None or an empty string, no explicit activation layer added here.\n",
    "\n",
    "        layers = MaxPooling2D((pool_size, pool_size))(layers)  \n",
    "    \n",
    "    layers = Flatten()(layers)\n",
    "\n",
    "    # Dense Layers\n",
    "    for i, hidden_units in enumerate(hiddens): \n",
    "        layers = Dense(\n",
    "            hidden_units,\n",
    "            use_bias=True,\n",
    "            # NO 'activation' argument here\n",
    "            bias_initializer=tf.keras.initializers.RandomNormal(seed=rng_seed),\n",
    "            kernel_initializer=tf.keras.initializers.RandomNormal(seed=rng_seed),\n",
    "        )(layers)\n",
    "\n",
    "        # Apply PReLU (or other chosen activation)\n",
    "        if activation_function_dense[i].lower() == 'prelu':\n",
    "            layers = PReLU(alpha_initializer=tf.keras.initializers.Constant(0.25))(layers) # No shared_axes for Dense\n",
    "        elif activation_function_dense[i].lower() == 'gelu':\n",
    "            layers = tf.keras.layers.Activation('gelu')(layers)\n",
    "        elif activation_function_dense[i]: # For 'elu', 'relu', etc.\n",
    "            layers = tf.keras.layers.Activation(activation_function_dense[i])(layers)\n",
    "        # If activation_function_dense[i] is None or an empty string, no explicit activation layer.\n",
    "\n",
    "    output_layer = Dense(\n",
    "        y_train.shape[-1],  \n",
    "        activation=\"linear\",\n",
    "        use_bias=True,\n",
    "        bias_initializer=tf.keras.initializers.RandomNormal(seed=rng_seed),\n",
    "        kernel_initializer=tf.keras.initializers.RandomNormal(seed=rng_seed),\n",
    "    )(layers)\n",
    "    \n",
    "    model = Model(inputs, output_layer)\n",
    "\n",
    "    if fold_no + ens_no == 2: \n",
    "        model.summary()\n",
    "\n",
    "    model.compile(loss=loss_function, optimizer=Adam(learning_rate=learning_rate)) \n",
    "    \n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10, monitor='val_loss', mode='auto', restore_best_weights=True, verbose=1) # restore_best_weights=1 is True\n",
    "\n",
    "    # Make sure my_callbacks is defined in this scope or passed as an argument\n",
    "    history = model.fit(X_train, y_train, epochs=epoch_max, batch_size=batch_size,\n",
    "                        validation_data=(X_test, y_test), callbacks=[early_stopping] + my_callbacks, verbose=0) # Added '+' for list concatenation\n",
    "\n",
    "    skill = model.evaluate(X_test, y_test, verbose=0)\n",
    "    pred = (model.predict(X_test) * y_std) + y_mean # Make sure y_std and y_mean are defined\n",
    "\n",
    "    R2_val = []\n",
    "    truth = (y_test * y_std) + y_mean\n",
    "    for latind in range(truth.shape[1] if truth.ndim > 1 else 1): # Handle if y_test is 1D output\n",
    "        y_lat = truth[:, latind] if truth.ndim > 1 else truth\n",
    "        y_pred_lat = pred[:, latind] if pred.ndim > 1 else pred\n",
    "        R2_val.append(r2_score(y_lat, y_pred_lat))\n",
    "    \n",
    "    model.save(os.path.join(output_dir,'model_fold'+str(fold_no)+'_ens'+str(ens_no)+'.h5'))\n",
    "    \n",
    "    return skill, history, pred, R2_val\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff17f61",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 12:59:52,705 - Training for fold 1 ensemble 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 143, 144, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 143, 144, 32)      320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 143, 144, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 71, 72, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 71, 72, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 71, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 35, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 40320)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                645136    \n",
      "                                                                 \n",
      " p_re_lu (PReLU)             (None, 16)                16        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " p_re_lu_1 (PReLU)           (None, 8)                 8         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654,873\n",
      "Trainable params: 654,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 12:59:53.060466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 169 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "2025-08-29 12:59:53.080629: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2025-08-29 12:59:53.439351: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 96.44MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-29 12:59:53.439542: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2025-08-29 12:59:54.267327: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2025-08-29 12:59:56.748352: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2025-08-29 12:59:56.748962: W tensorflow/core/kernels/conv_ops_gpu.cc:378] None of the algorithms provided by cuDNN frontend heuristics worked; trying fallback algorithms.  Conv: batch: 32\n",
      "in_depths: 1\n",
      "out_depths: 32\n",
      "in: 143\n",
      "in: 144\n",
      "data_format: 1\n",
      "filter: 3\n",
      "filter: 3\n",
      "filter: 1\n",
      "dilation: 1\n",
      "dilation: 1\n",
      "stride: 1\n",
      "stride: 1\n",
      "padding: 1\n",
      "padding: 1\n",
      "dtype: DT_FLOAT\n",
      "group_count: 1\n",
      "device_identifier: \"Tesla V100-SXM2-32GB sm_7.0 with 34072559616B RAM and 80 cores\"\n",
      "version: 1\n",
      "\n",
      "2025-08-29 12:59:56.766075: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 532.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-29 12:59:56.767093: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 203.95MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-29 12:59:56.769162: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 96.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-29 12:59:56.770304: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2025-08-29 12:59:56.771439: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at conv_ops.cc:1134 : NOT_FOUND: No algorithm worked!  Error messages:\n",
      "  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
      "  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
      "  Profiling failure on CUDNN engine eng2{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
      "  Profiling failure on CUDNN engine eng3{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 557843584 bytes.\n",
      "  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
      "  Profiling failure on CUDNN engine eng6{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 213856768 bytes.\n",
      "  Profiling failure on CUDNN engine eng12{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
      "  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
      "  Profiling failure on CUDNN engine eng30{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
      "  Profiling failure on CUDNN engine eng31{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 101248016 bytes.\n",
      "  Profiling failure on CUDNN engine eng34{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
      "  Profiling failure on CUDNN engine eng42{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "2 root error(s) found.\n  (0) NOT_FOUND: No algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng2{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng3{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 557843584 bytes.\n  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng6{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 213856768 bytes.\n  Profiling failure on CUDNN engine eng12{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng30{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng31{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 101248016 bytes.\n  Profiling failure on CUDNN engine eng34{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng42{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n\t [[{{node conv2d/Conv2D}}]]\n\t [[loss/mul/_101]]\n  (1) NOT_FOUND: No algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng2{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng3{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 557843584 bytes.\n  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng6{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 213856768 bytes.\n  Profiling failure on CUDNN engine eng12{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng30{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng31{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 101248016 bytes.\n  Profiling failure on CUDNN engine eng34{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng42{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n\t [[{{node conv2d/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ens_no  \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,NNrepeats\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    100\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining for fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ensemble \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mens_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m     skill, history, pred, R2_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     trained_models\u001b[38;5;241m.\u001b[39mappend((skill, skill, history\u001b[38;5;241m.\u001b[39mhistory, pred, R2_val))\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Increase fold number\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 205\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, X_test, y_test, y_mean, y_std)\u001b[0m\n\u001b[1;32m    202\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# restore_best_weights=1 is True\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Make sure my_callbacks is defined in this scope or passed as an argument\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmy_callbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Added '+' for list concatenation\u001b[39;00m\n\u001b[1;32m    208\u001b[0m skill \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    209\u001b[0m pred \u001b[38;5;241m=\u001b[39m (model\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;241m*\u001b[39m y_std) \u001b[38;5;241m+\u001b[39m y_mean \u001b[38;5;66;03m# Make sure y_std and y_mean are defined\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training_v1.py:855\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    854\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m         )\n\u001b[1;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/engine/training_arrays_v1.py:419\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[1;32m    415\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[1;32m    416\u001b[0m )\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    421\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/keras/backend.py:4577\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4568\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4569\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4573\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[1;32m   4574\u001b[0m ):\n\u001b[1;32m   4575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 4577\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[1;32m   4579\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   4580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[1;32m   4581\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[1;32m   4582\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4583\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/tf210/lib/python3.8/site-packages/tensorflow/python/client/session.py:1481\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1480\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1484\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1485\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) NOT_FOUND: No algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng2{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng3{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 557843584 bytes.\n  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng6{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 213856768 bytes.\n  Profiling failure on CUDNN engine eng12{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng30{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng31{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 101248016 bytes.\n  Profiling failure on CUDNN engine eng34{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng42{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n\t [[{{node conv2d/Conv2D}}]]\n\t [[loss/mul/_101]]\n  (1) NOT_FOUND: No algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng2{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng3{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 557843584 bytes.\n  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng6{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 213856768 bytes.\n  Profiling failure on CUDNN engine eng12{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng30{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng31{}: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 101248016 bytes.\n  Profiling failure on CUDNN engine eng34{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on CUDNN engine eng42{}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n\t [[{{node conv2d/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "#                             Train loop                              #\n",
    "#######################################################################\n",
    "# X = input\n",
    "# y = output\n",
    "\n",
    "# X_mean = np.mean(X, axis=0)\n",
    "# X_std = np.std(X, axis=0)\n",
    "\n",
    "# y_mean = np.mean(y, axis=0)\n",
    "# y_std = np.std(y, axis=0)\n",
    "\n",
    "# if remove_mean ==0:\n",
    "#     X_mean = 0\n",
    "#     y_mean = 0\n",
    "\n",
    "    \n",
    "    \n",
    "# if divide_std ==0:\n",
    "#     X_std = 1\n",
    "#     y_std = 1\n",
    "# else:\n",
    "#     X_std = X_std[:,:, tf.newaxis]\n",
    "    \n",
    "    \n",
    "    \n",
    "# sio.savemat(os.path.join(output_dir,'Normalization.mat'), \n",
    "#             {'X_mean': X_mean, 'X_std': X_std,'y_mean':y_mean,'y_std':y_std})\n",
    "\n",
    "# # if not os.path.exists(os.path.join(output_dir, 'inputs_info.mat')):\n",
    "\n",
    "        \n",
    "trained_models = []\n",
    "# y_pred_reconstructed_allfolds = []\n",
    "\n",
    "\n",
    "# # Train the neural network multiple times using k-fold cross validation\n",
    "# # Define the K-fold Cross Validator\n",
    "# kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "# fold_no = 1\n",
    "# for trainind, testind in kfold.split(X, y):   \n",
    "#     # break\n",
    "#     X_train = X[trainind,:,:, tf.newaxis]\n",
    "#     y_train = y[trainind,:]\n",
    "#     X_test = X[testind,:, :,tf.newaxis]\n",
    "#     y_test = y[testind,:]\n",
    " \n",
    "#     # Normalize the input and out data based on the information from the entire PI control run\n",
    "    \n",
    "    \n",
    "#     X_train = (X_train - X_mean)/X_std\n",
    "#     X_test = (X_test - X_mean)/X_std\n",
    "    \n",
    "#     y_train = (y_train - y_mean)/y_std\n",
    "#     y_test = (y_test - y_mean)/y_std\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Generate a print\n",
    "#     logger.info('------------------------------------------------------------------------')\n",
    "#     # We use ensemble training for each fold of the cross-validation\n",
    "X = input\n",
    "y = output\n",
    "\n",
    "# Train the neural network multiple times using k-fold cross validation\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "fold_no = 1\n",
    "for trainind, testind in kfold.split(X, y):\n",
    "    # --- Step 1: Split the data FIRST ---\n",
    "    X_train_raw = X[trainind]\n",
    "    y_train_raw = y[trainind]\n",
    "    X_test_raw = X[testind]\n",
    "    y_test_raw = y[testind]\n",
    "\n",
    "    # --- Step 2: Calculate normalization stats ONLY from the training data ---\n",
    "    X_mean = np.mean(X_train_raw, axis=0)\n",
    "    X_std = np.std(X_train_raw, axis=0)\n",
    "    y_mean = np.mean(y_train_raw, axis=0)\n",
    "    y_std = np.std(y_train_raw, axis=0)\n",
    "    \n",
    "    # Handle cases where you don't want to normalize\n",
    "    if remove_mean == 0:\n",
    "        X_mean = 0\n",
    "        y_mean = 0\n",
    "    if divide_std == 0:\n",
    "        X_std = 1\n",
    "        y_std = 1\n",
    "        \n",
    "    # --- Step 3: Normalize BOTH sets using the TRAINING stats ---\n",
    "    X_train = (X_train_raw - X_mean) / X_std\n",
    "    X_test = (X_test_raw - X_mean) / X_std # Use the mean/std from the train set\n",
    "\n",
    "    y_train = (y_train_raw - y_mean) / y_std\n",
    "    y_test = (y_test_raw - y_mean) / y_std # Use the mean/std from the train set\n",
    "    \n",
    "    # --- Step 4: Add the channel dimension for the CNN ---\n",
    "    X_train = X_train[..., tf.newaxis]\n",
    "    X_test = X_test[..., tf.newaxis]\n",
    "    for ens_no  in np.arange(1,NNrepeats+1):\n",
    "        logger.info(f'Training for fold {fold_no} ensemble {ens_no}...')\n",
    "        skill, history, pred, R2_val = train_model(X_train, y_train, X_test, y_test,y_mean,y_std)\n",
    "        trained_models.append((skill, skill, history.history, pred, R2_val))\n",
    "\n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "        \n",
    "        \n",
    "logger.info('------------------------------------------------------------------------')\n",
    "logger.info(f'Training with {num_folds}-fold cross-validation finished!') \n",
    "logger.info('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32e148",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "have a quick look at the performance of the trainined neural network"
   },
   "outputs": [],
   "source": [
    "\n",
    "skills = [trained_model[1] for trained_model in trained_models[0:num_folds*NNrepeats]]\n",
    "median_skill = np.median(skills)\n",
    "median_index = skills.index(median_skill)\n",
    "minimum_skill = np.min(skills)\n",
    "min_index = skills.index(minimum_skill)\n",
    "std_dev_skill = np.std(skills)\n",
    "\n",
    "formatted_skills = [f\"{skill:.4f}\" for skill in skills]\n",
    "logger.info(f\"Losses in testing set: {formatted_skills}\")\n",
    "fold_median = median_index // NNrepeats + 1  # Compute fold number\n",
    "ensemble_median = median_index % NNrepeats + 1  # Compute ensemble number\n",
    "logger.info(f\"Median Loss is: {median_skill:.4f}, which occurs at Fold {fold_median} Ensemble {ensemble_median}\")\n",
    "fold_min = min_index // NNrepeats + 1  # Compute fold number\n",
    "ensemble_min = min_index % NNrepeats + 1  # Compute ensemble number\n",
    "logger.info(f\"Minimum Loss is: {minimum_skill:.4f}, which occurs at Fold {fold_min} Ensemble {ensemble_min}\")\n",
    "logger.info(f\"Standard Deviation of the Loss is: {std_dev_skill:.4f}\")\n",
    "ratio = std_dev_skill/median_skill * 100\n",
    "logger.info(f\"Standard Deviation/Median: {ratio:.2f}%\")\n",
    "\n",
    "# Check if the standard deviation to median skill ratio is higher than 30%\n",
    "if ratio > 30:\n",
    "    warning_message = (\"Warning: The standard deviation of model skill across \"\n",
    "                       \"folds and ensembles is large!\\nStandard Deviation/Median Skill: {ratio:.2f}%\").format(ratio=ratio)\n",
    "    with open(os.path.join(output_dir,'Warning_'+names_str+'.txt'), \"w\") as file:\n",
    "        file.write(warning_message)\n",
    "    with open(os.path.join(output_dir,'..','Warning_'+names_str+'.txt'), \"w\") as file:\n",
    "        file.write(warning_message)\n",
    "\n",
    "\n",
    "# Plot the loss function during training for all folds\n",
    "# First, find the global minimum and maximum loss values across all folds\n",
    "min_loss = min(min(trained_models[i][2]['loss']+trained_models[i][2]['val_loss']) for i in range(num_folds))\n",
    "max_loss = max(max(trained_models[i][2]['loss']+trained_models[i][2]['val_loss']) for i in range(num_folds))\n",
    "\n",
    "plt.figure(figsize=(9, 12))\n",
    "\n",
    "# Plot the first fold outside the loop to avoid repeating the legend setting\n",
    "plt.subplot(num_folds, 1, 1)\n",
    "for nn in range(NNrepeats):\n",
    "    plt.plot(trained_models[nn][2]['loss'],'-k')\n",
    "    plt.plot(trained_models[nn][2]['val_loss'],'-r')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')  # Set logarithmic scale\n",
    "plt.ylim(min_loss, max_loss)  # Set the same y-limits for all subplots\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Now plot the remaining folds\n",
    "for n in range(1, num_folds):\n",
    "    plt.subplot(num_folds, 1, n+1)\n",
    "    for nn in range(NNrepeats):\n",
    "        plt.plot(trained_models[n*NNrepeats+nn][2]['loss'],'-k')\n",
    "        plt.plot(trained_models[n*NNrepeats+nn][2]['val_loss'],'-r')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')  # Set logarithmic scale\n",
    "    plt.ylim(min_loss, max_loss)  # Set the same y-limits for all subplots\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplots_adjust(hspace=0.5)  # Adjust space between plots if needed\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'TrainingLoss_' + names_str  + '.png'),dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "R2_each_fold_ens = [trained_models[i][4] for i in range(0,num_folds*NNrepeats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22894312",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "Model_preds = [np.concatenate([trained_models[n*NNrepeats + i][3] for n in range(num_folds)]) for i in range(NNrepeats)]\n",
    "Model_pred = np.mean(Model_preds,axis=0)\n",
    "Model_error = Model_pred - y\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 6))  \n",
    "plt.plot(time, y, label=\"Truth\", color=\"C0\", linewidth=2)  # Use color and linewidth\n",
    "plt.plot(time, Model_pred, label=\"Prediction\", color=\"C1\", linestyle=\"-\", linewidth=1.5)  # Dashed line for prediction\n",
    "plt.xlabel(\"Time (year)\", fontsize=14)\n",
    "plt.ylabel(names_str, fontsize=14)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend(fontsize=12, loc=\"best\")\n",
    "r2 = r2_score(y, Model_pred)\n",
    "plt.text(0.05, 0.9, f\"$R^2$: {r2:.3f}\", transform=plt.gca().transAxes,\n",
    "         fontsize=14, bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"black\"))\n",
    "plt.savefig(os.path.join(output_dir, names_str+\"_TruthvsPred.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "######### scatter plot\n",
    "\n",
    "plt.figure(figsize=(8, 8))  # Keep square aspect ratio\n",
    "\n",
    "# Scatter plot with adjusted marker size and transparency\n",
    "plt.plot(Model_pred, y, 'o', markersize=5, alpha=0.6, color=\"C0\", label=\"Data Points\")\n",
    "\n",
    "# Compute common limits based on both Model_pred and y\n",
    "min_val = min(np.min(Model_pred), np.min(y))\n",
    "max_val = max(np.max(Model_pred), np.max(y))\n",
    "\n",
    "# Set same limits for x and y\n",
    "plt.xlim(min_val, max_val)\n",
    "plt.ylim(min_val, max_val)\n",
    "\n",
    "# Define consistent tick locations\n",
    "num_ticks = 6  # Adjust this for more or fewer ticks\n",
    "ticks = np.linspace(min_val, max_val, num_ticks)\n",
    "\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks)\n",
    "\n",
    "# 1:1 Reference Line\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, label=\"1:1 Reference\")\n",
    "\n",
    "# Labels and formatting\n",
    "plt.xlabel(\"Prediction\", fontsize=16, fontweight='bold')\n",
    "plt.ylabel(\"Truth\", fontsize=16, fontweight='bold')\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Compute and display R² score\n",
    "r2 = r2_score(y, Model_pred)\n",
    "plt.text(0.05, 0.9, f\"$R^2$: {r2:.3f}\", transform=plt.gca().transAxes,\n",
    "         fontsize=14, bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"black\"))\n",
    "\n",
    "# Equal aspect ratio for fair comparison\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "# Add legend (only for reference line)\n",
    "plt.legend(fontsize=12, loc=\"center left\")\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(os.path.join(output_dir, \"TOA_TruthvsPred_scatter.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fc216",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "copy this script to the directory that stores the trained NN"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def copy_script(target_directory):\n",
    "    # Get the current script file path\n",
    "    current_script = \"try_withGelu.ipynb\"\n",
    "    # current_script = script_path_and_name\n",
    "    \n",
    "    # Ensure the target directory exists, create if it does not\n",
    "    os.makedirs(target_directory, exist_ok=True)\n",
    "    \n",
    "    # Define the target path for the script\n",
    "    target_path = os.path.join(target_directory, os.path.basename(current_script))\n",
    "    \n",
    "    # Copy the script\n",
    "    shutil.copy(current_script, target_path)\n",
    "    logger.info(f\"Script copied to {target_path}\")\n",
    "\n",
    "# Example usage\n",
    "copy_script(output_dir)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e12b1a-4c08-4287-bdc0-bffc8d091e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (tf210)",
   "language": "python",
   "name": "tf210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
